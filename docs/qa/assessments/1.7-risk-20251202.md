# Enhanced Risk Profile: Story 1.7: Stream Monitor Worker

**Date**: 2025-12-02  
**Reviewer**: Quinn (Test Architect)  
**Status**: Updated & Finalized for Architect Review

## 1. Executive Summary

Story 1.7 (Stream Monitor Worker) contains three critical risks that, if implemented as originally designed, would result in a non-functional and dangerous system. The original design for keyword matching is O(n*m) inefficient, the worker management is fragile, and the automated Reddit karma strategy is a Terms of Service violation that guarantees an account ban.

This enhanced assessment provides mandatory, production-grade replacements for these flawed components.

- **Total Risks Identified**: 5
- **Critical Risks (Score 9)**: 3 (Performance, Reliability, Business/ToS)
- **High Risks (Score 6-8)**: 1
- **Overall Assessment**: **NO-GO**. The story requires immediate architectural intervention to prevent the deployment of a system that will crash under load and get the project banned from Reddit.

## 2. Detailed Risk Register

| Risk ID | Description | Category | Probability (1-3) | Impact (1-3) | Score (PÃ—I) | Priority |
| :--- | :--- | :--- | :--- | :--- | :--- | :--- |
| **PERF-001** | **Inefficient Keyword Matching (O(n*m) Loop)** | Performance | 3 (High) | 3 (High) | **9** | **CRITICAL** |
| **TECH-001** | **Fragile Custom Worker Manager** | Reliability | 3 (High) | 3 (High) | **9** | **CRITICAL** |
| **BUS-001** | **Automated Reddit Karma "Farming"** | Business | 3 (High) | 3 (High) | **9** | **CRITICAL** |
| **DATA-001** | **Data Duplication on Worker Restart** | Data Integrity | 3 (High) | 2 (Medium) | **6** | **HIGH** |
| **TECH-002** | **Hardcoded Temporal Multipliers** | Maintainability | 3 (High) | 1 (Low) | **3** | **LOW** |

---

## 3. Actionable Mitigation & Implementation Plan

**This section is for the Architect Agent.** The following architectural patterns and implementations must be integrated into the `Dev Notes` and `Tasks` of Story 1.7.

---

### **CRITICAL RISK: Inefficient Keyword Matching (PERF-001)**
**Problem**: The initial design suggests iterating through 200+ keywords for every single post. With 1000 posts/minute, this results in 200,000 operations/minute, causing CPU exhaustion and lag.

**Mitigation & Implementation**:
1.  **Use Compiled Regular Expressions (O(1))**: Instead of a loop, use a single pre-compiled Regex to match any of the keywords in one pass.
    *   **Action**: Implement the `KeywordMatcher` class:
        ```typescript
        // backend/src/workers/keyword-matcher.ts
        export class KeywordMatcher {
          private regex: RegExp;
          
          constructor(keywords: string[]) {
            // Escape special chars and join with OR pipe
            const pattern = keywords.map(k => k.replace(/[.*+?^${}()|[\\]/g, '\\$&')).join('|');
            // Create a single regex with word boundaries
            this.regex = new RegExp(`\\b(${pattern})\\b`, 'i');
          }
          
          matches(text: string): boolean {
            return this.regex.test(text);
          }
        }
        ```
2.  **Push Filtering to the Edge**: Whenever possible, use the platform API's filtering capabilities (e.g., Twitter Advanced Search `OR` operator) to reduce the volume of data the worker needs to process.

### **CRITICAL RISK: Fragile Custom Worker Manager (TECH-001)**
**Problem**: The proposed `WorkerManager` lacks error isolation. A crash in one worker thread will bring down the entire Node.js process. It also lacks robust auto-restart capabilities.

**Mitigation & Implementation**:
1.  **Use `pm2` for Process Management**: Do not write a custom manager. Use `pm2`, the industry standard for Node.js process management.
    *   **Action**: Add `pm2` to `devDependencies`.
    *   **Action**: Create `ecosystem.config.js` instead of `WorkerManager.ts`:
        ```javascript
        module.exports = {
          apps: [{
            name: 'reply-bot-worker',
            script: 'dist/workers/stream-monitor.js',
            instances: 1,
            autorestart: true,
            watch: false,
            max_memory_restart: '500M',
            env: { NODE_ENV: 'production' }
          }]
        };
        ```
2.  **Alternative (If code solution required)**: Use Node.js `worker_threads` with a supervisor pattern that listens for the `exit` event and restarts the worker.

### **CRITICAL RISK: Automated Reddit Karma "Farming" (BUS-001)**
**Problem**: Automating comments to "build karma" is a violation of Reddit's manipulative content policies. It will trigger spam filters and permanently ban the account.

**Mitigation & Implementation**:
1.  **Strict Prohibition of Automation**: Remove all logic related to automated karma building.
2.  **Manual-First Strategy**: Explicitly state that karma building is a manual process.
    *   **Action**: Add a "Karma Gate" check that *prevents* the bot from acting if karma is too low, rather than trying to fix it automatically.
        ```typescript
        // backend/src/workers/guards/karma-gate.ts
        export async function checkKarma(redditClient: RedditClient): Promise<boolean> {
          const karma = await redditClient.getKarma();
          if (karma < 50) {
            logger.warn(`Karma too low (${karma}). Manual intervention required to build credibility.`);
            return false; // STOP. Do not post.
          }
          return true;
        }
        ```

### **HIGH RISK: Data Duplication on Worker Restart (DATA-001)**
**Problem**: If the worker crashes after processing a post but before updating the "last processed ID", the post will be processed again on restart.

**Mitigation & Implementation**:
1.  **Idempotent Database Writes (Upsert)**: Ensure that saving a post is an idempotent operation.
    *   **Action**: Use Prisma's `upsert` method.
        ```typescript
        await prisma.post.upsert({
          where: { 
            platform_platformPostId: { 
              platform: 'TWITTER', 
              platformPostId: tweet.id 
            } 
          },
          update: {}, // Do nothing if exists
          create: { ...postData }
        });
        ```
2.  **Unique Constraints**: Ensure the database schema has a `@@unique([platform, platformPostId])` constraint.

---

## 4. Final Recommendation

Story 1.7 is **NO-GO** in its current form. The Architect MUST replace the custom `WorkerManager` with `pm2` configuration, replace the loop-based keyword matching with the Regex solution, and remove the automated karma farming logic. These are non-negotiable for a functioning production system.