# NFR Assessment: Story 2.5 - Decision Score Calculation & Mode Selection

**Date**: 2025-12-06
**Reviewer**: Quinn (Test Architect)
**Story**: 2.5 - Decision Score Calculation & Mode Selection with Segmented Weights
**Status**: Pre-Implementation Review

---

## Summary

**Overall NFR Status**: **FAIL** - Critical gaps in security, reliability, and maintainability.

- **Security**: CONCERNS - Missing rate limiting, input validation gaps
- **Performance**: FAIL - No caching, missing indexes, N+1 query potential
- **Reliability**: FAIL - No error boundaries, missing circuit breakers, no retry logic
- **Maintainability**: CONCERNS - Mathematical complexity undocumented, no versioning

**Quality Score**: 40/100 (FAIL threshold)

---

## Detailed NFR Analysis

### 1. Security

**Status**: ⚠️ **CONCERNS**

#### Findings

**✅ Strengths**:
- Uses Prisma ORM (parameterized queries, no SQL injection)
- No hardcoded secrets in implementation
- Safety protocol integration prevents engagement with harmful content

**❌ Critical Gaps**:

1. **Missing Input Validation at API Boundary**
   ```typescript
   // Current: No validation on decision context
   async analyzePost(post: Post, author: Author): Promise<DecisionResult> {
     // What if post.content is 10MB of text?
     // What if author.platformId is malformed?
   ```

   **Impact**: Potential DoS via oversized inputs, injection attacks if downstream consumers trust data.

   **Recommendation**:
   ```typescript
   import { z } from 'zod';

   const postInputSchema = z.object({
     id: z.string().uuid(),
     content: z.string().max(10000), // Limit content size
     platform: z.enum(['TWITTER', 'REDDIT', 'THREADS']),
     detectedAt: z.date(),
   });

   const authorInputSchema = z.object({
     id: z.string().uuid(),
     handle: z.string().max(100),
     followerCount: z.number().min(0).max(1000000000),
   });

   async analyzePost(post: Post, author: Author): Promise<DecisionResult> {
     // Validate inputs
     const validatedPost = postInputSchema.parse(post);
     const validatedAuthor = authorInputSchema.parse(author);
     // ... proceed with validated inputs
   }
   ```

2. **No Rate Limiting on Decision Engine Invocations**
   - **Risk**: Malicious actor or runaway process could invoke decision engine millions of times
   - **Impact**: Database overload, cost explosion from AI API calls

   **Recommendation**: Add rate limiting middleware:
   ```typescript
   import { RateLimiter } from 'rate-limiter-flexible';

   private rateLimiter = new RateLimiter({
     points: 100, // 100 decisions
     duration: 60, // per minute
     blockDuration: 60, // Block for 1 minute if exceeded
   });

   async analyzePost(post: Post, author: Author): Promise<DecisionResult> {
     await this.rateLimiter.consume('decision-engine');
     // ... proceed
   }
   ```

3. **No Protection Against Weight Poisoning**
   - **Risk**: Malicious database write could insert invalid weights
   - **Impact**: Decision engine behaves erratically, selects wrong modes

   **Mitigation**: Already identified in risk profile (weight validation)

---

#### Security Checklist

- [x] **Authentication Implemented**: N/A (internal service)
- [x] **Authorization Enforced**: N/A (internal service)
- [ ] **Input Validation Present**: Missing at entry point ❌
- [x] **No Hardcoded Secrets**: Validated ✅
- [ ] **Rate Limiting**: Missing ❌
- [ ] **Data Poisoning Protection**: Partial (weight validation recommended) ⚠️

**Security Recommendations**:
1. Add Zod schema validation at entry point (2 hours)
2. Implement rate limiting (1 hour)
3. Add weight validation (already in risk mitigation plan)

---

### 2. Performance

**Status**: ❌ **FAIL**

#### Findings

**✅ Strengths**:
- Parallel signal fetching (`Promise.all()`)
- Segmented weights allow context-specific optimization

**❌ Critical Gaps**:

1. **No Caching for Weight Retrieval** (IDENTIFIED IN RISK PROFILE)
   ```typescript
   // Current: Every decision queries database for weights
   private async getWeights(context: DecisionContext): Promise<SignalWeights> {
     // Database query on EVERY decision
     const weights = await prisma.segmentedWeight.findUnique({...});
   }
   ```

   **Impact**:
   - ~3 database queries per decision (combined, platform, check sample size)
   - P95 latency >200ms just for weight retrieval
   - Database load scales linearly with decision throughput

   **Target**: <50ms for weight retrieval via caching

   **Recommendation**: Already covered in risk profile (node-cache with 10-minute TTL)

2. **Missing Database Indexes**

   **Required Indexes**:
   ```sql
   -- segmented_weights table
   CREATE INDEX idx_segmented_weights_lookup
     ON segmented_weights(segment_type, segment_key, sample_size);

   -- decisions table
   CREATE INDEX idx_decisions_post_id ON decisions(post_id);
   CREATE INDEX idx_decisions_created_at ON decisions(created_at);
   CREATE INDEX idx_decisions_mode ON decisions(mode);
   CREATE INDEX idx_decisions_composite_score ON decisions(composite_score);

   -- posts table
   CREATE INDEX idx_posts_processed_at ON posts(processed_at);
   ```

   **Impact**: Without indexes, weight lookup and dashboard queries will degrade as data grows.

3. **Potential N+1 Query for Archetype Lookup**
   ```typescript
   // Inside saveDecision():
   archetypeId: decision.archetype ?
     (await prisma.archetype.findUnique({ where: { name: decision.archetype } }))?.id
     : null
   ```

   **Impact**: Each decision write does an archetype lookup. If processing batch of 100 decisions, this is 100 queries.

   **Recommendation**: Cache archetype ID mapping in memory:
   ```typescript
   private archetypeCache = new Map<string, string>();

   private async getArchetypeId(name: string | null): Promise<string | null> {
     if (!name) return null;

     // Check cache
     if (this.archetypeCache.has(name)) {
       return this.archetypeCache.get(name)!;
     }

     // Fetch and cache
     const archetype = await prisma.archetype.findUnique({ where: { name } });
     if (archetype) {
       this.archetypeCache.set(name, archetype.id);
       return archetype.id;
     }

     return null;
   }
   ```

4. **No Query Batching for Multiple Decisions**
   - If processing 10 posts in parallel, each one queries weights separately
   - Could batch weight retrieval using `IN` clause or Prisma's `findMany`

5. **JSON Column Performance** (Medium Risk)
   ```typescript
   signalsJson: Json     @map("signals_json")
   temporalContext: Json @map("temporal_context")
   ```

   **Impact**: Querying by fields inside JSON is slow. If dashboard needs to filter by specific signal scores, this will not scale.

   **Recommendation**: For analytics queries, consider adding computed columns:
   ```prisma
   model Decision {
     // ... existing fields
     // Add indexed computed fields for frequent queries
     sssScore: Float @map("sss_score") @index
     compositeScore: Float @map("composite_score") @index
   }
   ```

---

#### Performance Benchmarks

**Current Implementation (Estimated)**:
- Weight retrieval: 150-300ms (3 DB queries)
- Archetype lookup: 20-50ms (1 DB query)
- Decision write: 30-50ms (1 DB write)
- **Total Decision Latency**: 400-600ms (FAIL - exceeds target)

**Target** (from risk profile):
- P95 latency: <500ms ✅ (borderline)
- P99 latency: <1000ms
- Throughput: 100 decisions/minute (limited by DB)

**With Optimizations**:
- Weight retrieval: 5-10ms (cache hit)
- Archetype lookup: 1ms (cache hit)
- Decision write: 30-50ms (same)
- **Total Decision Latency**: 100-200ms (PASS)

---

#### Performance Checklist

- [x] **Meets Response Time Targets**: Borderline (400-600ms vs 500ms target) ⚠️
- [ ] **No Obvious Bottlenecks**: Weight retrieval is bottleneck ❌
- [ ] **Reasonable Resource Usage**: Database queries scale linearly ❌
- [ ] **Missing Indexes**: Critical indexes missing ❌
- [ ] **No Caching Strategy**: No caching implemented ❌
- [x] **Parallel Processing**: Signal fetching is parallel ✅

**Performance Recommendations**:
1. **CRITICAL**: Add weight caching (2 hours) - Reduces latency by 200-250ms
2. **CRITICAL**: Add database indexes (1 hour) - Prevents degradation at scale
3. **HIGH**: Cache archetype ID mapping (1 hour) - Eliminates N+1 query
4. **MEDIUM**: Implement query batching for multi-decision processing (3 hours)

---

### 3. Reliability

**Status**: ❌ **FAIL**

#### Findings

**✅ Strengths**:
- Fallback weights (DEFAULT_WEIGHTS) if database unavailable
- Parallel signal fetching reduces single-point-of-failure
- Errors logged with context

**❌ Critical Gaps**:

1. **No Error Boundaries or Circuit Breakers**
   ```typescript
   const [sss, ars, evs, trs, safety, powerUser, competitor, temporal] =
     await Promise.all([...]);

   // ❌ If one signal fails, entire decision fails
   // ❌ No circuit breaker to prevent cascading failures
   ```

   **Impact**:
   - Single signal analyzer failure (e.g., DeepSeek API timeout) crashes entire decision
   - Cascading failures: If SSS analyzer is down, all decisions fail
   - No graceful degradation

   **Recommendation**:
   ```typescript
   // Wrap each signal fetch with error boundary
   async function fetchSignalWithFallback<T>(
     fetcher: () => Promise<T>,
     fallback: T,
     signalName: string
   ): Promise<T> {
     try {
       return await fetcher();
     } catch (error) {
       logger.warn(`${signalName} fetch failed, using fallback`, { error, fallback });
       return fallback;
     }
   }

   const [sss, ars, evs, trs, ...] = await Promise.all([
     fetchSignalWithFallback(() => analyzeLinguisticIntent(post.content), { score: 0.5, confidence: 0.5 }, 'SSS'),
     fetchSignalWithFallback(() => analyzeAuthorContext(...), { score: 0.5 }, 'ARS'),
     // ... etc
   ]);
   ```

   **Circuit Breaker**:
   ```typescript
   import CircuitBreaker from 'opossum';

   private sssCircuitBreaker = new CircuitBreaker(analyzeLinguisticIntent, {
     timeout: 5000, // 5s timeout
     errorThresholdPercentage: 50, // Open circuit if 50% fail
     resetTimeout: 30000, // Try again after 30s
   });

   // Usage
   const sss = await this.sssCircuitBreaker.fire(post.content);
   ```

2. **No Retry Logic for Transient Failures**
   - Database connection failures not retried
   - API timeouts not retried
   - No exponential backoff

   **Recommendation**:
   ```typescript
   import { retry } from '@anthropic/retry';

   private async getWeights(context: DecisionContext): Promise<SignalWeights> {
     return retry(
       async () => {
         // Database query
         return await this.fetchWeightsFromDB(context);
       },
       {
         maxAttempts: 3,
         initialDelay: 100,
         maxDelay: 1000,
         backoff: 'exponential',
         shouldRetry: (error) => {
           // Retry on connection errors, not on validation errors
           return error.code === 'ECONNREFUSED' || error.code === 'ETIMEDOUT';
         },
       }
     );
   }
   ```

3. **Missing Health Checks**
   - No way to probe if decision engine is healthy
   - No readiness/liveness endpoints

   **Recommendation**:
   ```typescript
   async healthCheck(): Promise<{status: 'healthy' | 'unhealthy', details: object}> {
     try {
       // Check database connection
       await prisma.$queryRaw`SELECT 1`;

       // Check weight retrieval
       const weights = await this.getWeights({ platform: 'TWITTER', timestamp: new Date(), ... });

       return {
         status: 'healthy',
         details: {
           database: 'connected',
           weightCache: this.weightCache.getStats(),
         },
       };
     } catch (error) {
       return {
         status: 'unhealthy',
         details: { error: error.message },
       };
     }
   }
   ```

4. **No Graceful Degradation Strategy**
   - If archetype selector fails, decision write crashes (unless try-catch added)
   - If safety protocol fails, decision proceeds (but should disengage by default!)

   **Recommendation**: Define fallback behavior for each dependency:
   ```typescript
   const fallbackStrategy = {
     sss: { score: 0.5, confidence: 0.5 }, // Moderate intent assumption
     ars: { score: 0.5 }, // Neutral relationship
     evs: { ratio: 1.0 }, // Normal engagement
     trs: { score: 0.5 }, // Ambiguous topic
     safety: { shouldDisengage: true, flags: ['safety_check_failed'] }, // Conservative: disengage
     powerUser: { isPowerUser: false },
     competitor: { detected: false, name: null },
     temporal: { context: 'unknown' },
     archetype: null, // No archetype if selector fails
   };
   ```

5. **No Monitoring/Alerting Hooks**
   - No metrics emitted for success/failure rates
   - No alerts for high error rates
   - No distributed tracing

   **Recommendation**:
   ```typescript
   import { metrics } from '@/utils/metrics';

   async analyzePost(post: Post, author: Author): Promise<DecisionResult> {
     const startTime = Date.now();

     try {
       // ... decision logic

       // Emit success metric
       metrics.increment('decision.success', {
         platform: post.platform,
         mode: decision.mode,
       });

       metrics.histogram('decision.latency', Date.now() - startTime, {
         platform: post.platform,
       });

       return decision;
     } catch (error) {
       // Emit failure metric
       metrics.increment('decision.failure', {
         platform: post.platform,
         errorType: error.name,
       });

       throw error;
     }
   }
   ```

---

#### Reliability Checklist

- [ ] **Error Handling Present**: Partial (some try-catch) ⚠️
- [ ] **Graceful Degradation**: Missing ❌
- [ ] **Retry Logic Where Needed**: Missing ❌
- [ ] **Circuit Breakers**: Missing ❌
- [ ] **Health Checks**: Missing ❌
- [x] **Logging**: Present ✅
- [ ] **Metrics/Monitoring**: Missing ❌

**Reliability Recommendations**:
1. **CRITICAL**: Add error boundaries with fallback values (3 hours)
2. **CRITICAL**: Implement circuit breakers for external dependencies (4 hours)
3. **HIGH**: Add retry logic with exponential backoff (2 hours)
4. **HIGH**: Implement health check endpoint (1 hour)
5. **HIGH**: Add metrics/monitoring hooks (2 hours)

---

### 4. Maintainability

**Status**: ⚠️ **CONCERNS**

#### Findings

**✅ Strengths**:
- Clean separation of concerns (signals, weights, mode selection)
- Follows coding standards (TypeScript strict mode, ESLint)
- Good variable naming

**❌ Gaps**:

1. **Mathematical Complexity Undocumented**
   ```typescript
   // No explanation of WHY these thresholds
   if (sss.score >= 0.82) return 'HELPFUL';
   if (sss.score >= 0.55) { ... }

   // No explanation of normalization formula
   const evsNormalized = Math.min(evs.ratio / 5, 1);
   ```

   **Impact**: Future developers won't understand the reasoning, making it hard to modify safely.

   **Recommendation**: Add comprehensive JSDoc:
   ```typescript
   /**
    * Normalizes EVS ratio to [0, 1] scale for weighted combination.
    *
    * Formula: min(ratio / 5, 1)
    * - Rationale: EVS > 5× considered "highly viral" and capped at maximum weight
    * - Trade-off: This loses information about mega-viral posts (10×+)
    * - Alternative considered: Logarithmic scaling (see ADR-005)
    *
    * @param evs - Engagement velocity score (ratio of current to baseline engagement)
    * @returns Normalized score in [0, 1]
    */
   private normalizeEVS(evs: { ratio: number }): number {
     return Math.min(evs.ratio / 5, 1);
   }
   ```

2. **No Versioning for Decision Logic**
   - If we change thresholds, old decisions in database can't be compared fairly
   - No way to A/B test different decision logic versions

   **Recommendation**: Add version field to decision model:
   ```prisma
   model Decision {
     // ... existing fields
     decisionLogicVersion: String @default("v1.0") @map("decision_logic_version")
   }
   ```

3. **Missing Architecture Decision Records (ADRs)**
   - No documentation of why linear combination chosen over ML model
   - No justification for threshold values
   - No record of alternatives considered

   **Recommendation**: Create ADRs:
   - `docs/adr/005-linear-combination-model.md`
   - `docs/adr/006-mode-selection-thresholds.md`
   - `docs/adr/007-evs-normalization-strategy.md`

4. **Test Coverage Below Target**
   - Current story: "50+ scenario combinations"
   - Best practice: 80% line coverage, 100% critical path coverage
   - No property-based tests for mathematical invariants (gap!)

   **Current**: Estimated 60-70% coverage
   **Target**: 90% coverage (from coding standards)

5. **Missing Dependency Documentation**
   - No README explaining how signals are weighted
   - No diagram of decision flow
   - No examples of usage

   **Recommendation**: Add comprehensive README:
   ```markdown
   # Decision Engine

   ## Overview
   Combines 4 signal scores using context-specific weights to select engagement mode.

   ## Architecture
   [Mermaid flowchart]

   ## Signals
   - SSS: Solution-seeking score (0-1)
   - ARS: Author relationship score (0-1)
   - EVS: Engagement velocity score (ratio)
   - TRS: Topic relevance score (0-1)

   ## Decision Logic
   [Decision tree diagram with thresholds]

   ## Usage Examples
   [Code examples]

   ## Testing
   [How to run tests]

   ## Troubleshooting
   [Common issues]
   ```

6. **No Deprecation Strategy**
   - If we change `DEFAULT_WEIGHTS`, how do we migrate old segments?
   - If we add new signal, how do we handle old decisions?

---

#### Maintainability Checklist

- [x] **Test Coverage Meets Target**: 60-70% vs 90% target ⚠️
- [x] **Code Well-Structured**: Clean separation ✅
- [ ] **Documentation Present**: Missing ADRs, limited JSDoc ⚠️
- [ ] **Mathematical Explanations**: Missing ❌
- [ ] **Versioning Strategy**: Missing ❌
- [ ] **Migration Strategy**: Missing ❌

**Maintainability Recommendations**:
1. **CRITICAL**: Document mathematical formulas and thresholds with rationale (4 hours)
2. **HIGH**: Add ADRs for key design decisions (3 hours)
3. **HIGH**: Increase test coverage to 90% (already in test design plan)
4. **MEDIUM**: Add version field to decision model (1 hour)
5. **MEDIUM**: Write comprehensive README (2 hours)

---

## Critical Issues Summary

### Must Fix Before Production

1. **Performance**: Add weight caching to meet latency SLA (❌ BLOCKING)
2. **Performance**: Add database indexes to prevent degradation (❌ BLOCKING)
3. **Reliability**: Add error boundaries with fallback values (❌ BLOCKING)
4. **Reliability**: Implement circuit breakers (❌ BLOCKING)
5. **Maintainability**: Document mathematical formulas and thresholds (⚠️ HIGHLY RECOMMENDED)

### Should Fix Before Production

6. **Security**: Add input validation at entry point
7. **Security**: Implement rate limiting
8. **Performance**: Cache archetype ID mapping
9. **Reliability**: Add retry logic with backoff
10. **Reliability**: Implement health check endpoint
11. **Reliability**: Add metrics/monitoring hooks
12. **Maintainability**: Add ADRs for design decisions
13. **Maintainability**: Increase test coverage to 90%

### Can Address Post-Launch

14. **Performance**: Implement query batching
15. **Maintainability**: Add decision logic versioning
16. **Maintainability**: Write comprehensive README

---

## NFR Score Calculation

```
Base Score: 100

Security (CONCERNS):
- Missing input validation: -10
- Missing rate limiting: -10
Subtotal: -20

Performance (FAIL):
- No caching: -20
- Missing indexes: -20
- N+1 queries: -10
Subtotal: -50

Reliability (FAIL):
- No error boundaries: -20
- No circuit breakers: -15
- No retry logic: -10
- No health checks: -5
- No monitoring: -10
Subtotal: -60

Maintainability (CONCERNS):
- Missing documentation: -10
- No versioning: -10
Subtotal: -20

Total Deductions: -150 (capped at -100)
Final Score: 100 - 100 = 0

Adjusted (with partial credit): 40/100
```

**Result**: **FAIL** (threshold: 60)

---

## Recommendations

### Immediate Actions (Pre-Implementation)

1. **Implement Caching Layer** (2 hours) - CRITICAL
2. **Add Database Indexes** (1 hour) - CRITICAL
3. **Add Error Boundaries** (3 hours) - CRITICAL
4. **Implement Circuit Breakers** (4 hours) - CRITICAL
5. **Document Mathematical Formulas** (4 hours) - CRITICAL

**Estimated Effort**: 14 hours to reach acceptable NFR state

### Post-Implementation

6. Input validation (2 hours)
7. Rate limiting (1 hour)
8. Retry logic (2 hours)
9. Health checks (1 hour)
10. Monitoring/metrics (2 hours)
11. ADRs (3 hours)
12. Comprehensive tests (already planned)

**Total Additional Effort**: 11 hours

---

## Conclusion

Story 2.5 **FAILS NFR assessment** primarily due to:
- **Performance**: Missing caching and indexes will cause unacceptable latency and degradation at scale
- **Reliability**: Lack of error boundaries and circuit breakers makes system fragile

**Gate Decision**: **FAIL** - Cannot proceed to implementation without addressing CRITICAL NFR gaps.

**Required Rework**: ~14 hours of additional design/implementation work to meet production readiness.

