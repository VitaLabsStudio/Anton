# Story 2.1: Signal 1 - Linguistic Intent Analyzer

## Status: Draft

## Story

**As a** the decision engine,  
**I want** to analyze post text for solution-seeking language patterns,  
**so that** I can calculate a Solution-Seeking Score (SSS) indicating whether the user wants help or is just venting/joking.

## Acceptance Criteria

1. Module created at `@backend/analysis/signal-1-linguistic.ts`
2. **DeepSeek R1 API integration** for text classification with GPT-4 fallback:
   - Primary: DeepSeek R1 (`deepseek-reasoner` model) - $0.55/1M input tokens
   - Fallback: GPT-4 if DeepSeek fails or confidence <0.85
   - Client: `@backend/clients/deepseek.ts`
3. Prompt engineering: Classify text as `high_solution` (0.82-1.0), `moderate` (0.55-0.82), or `low_solution` (0.0-0.55)
4. Examples from project brief used to train prompt
5. Function returns SSS score as float between 0.0-1.0
6. Unit tests with 20+ example posts validate score accuracy (>85% match expected categories)
7. Processing time <2 seconds per post (cached results for duplicate text)
8. Errors handled gracefully (API timeout â†’ default to 0.5 moderate score)

---

## Tasks / Subtasks

- [ ] **Task 1: Create DeepSeek Client** (AC: 2)
  - [ ] Create `backend/src/clients/deepseek.ts`
  - [ ] Implement API wrapper for DeepSeek R1
  - [ ] Add confidence extraction from response
  - [ ] Implement GPT-4 fallback when confidence <0.85
  - [ ] Add retry logic with exponential backoff
  - [ ] Add request/response logging

- [ ] **Task 2: Create Linguistic Intent Module** (AC: 1, 3, 4, 5)
  - [ ] Create `backend/src/analysis/signal-1-linguistic.ts`
  - [ ] Implement `analyzeLinguisticIntent(content: string)` function
  - [ ] Build prompt with classification categories
  - [ ] Include example posts from project brief
  - [ ] Parse response and extract SSS score (0.0-1.0)
  - [ ] Return SignalResult with score and confidence

- [ ] **Task 3: Implement Caching** (AC: 7)
  - [ ] Add Redis or in-memory cache for results
  - [ ] Cache key: hash of post content
  - [ ] TTL: 7 days
  - [ ] Test cache hit rate with duplicate posts

- [ ] **Task 4: Implement Error Handling** (AC: 8)
  - [ ] Wrap API calls in try/catch
  - [ ] Default to 0.5 on timeout
  - [ ] Log errors with context
  - [ ] Track error rate metric

- [ ] **Task 5: Create Prompt Template** (AC: 3, 4)
  - [ ] Define classification categories
  - [ ] Add example posts for each category
  - [ ] Include context about solution-seeking vs venting
  - [ ] Test prompt with diverse examples

- [ ] **Task 6: Write Unit Tests** (AC: 6)
  - [ ] Create test suite with 20+ example posts
  - [ ] Test high_solution posts (0.82-1.0)
  - [ ] Test moderate posts (0.55-0.82)
  - [ ] Test low_solution posts (0.0-0.55)
  - [ ] Verify >85% accuracy
  - [ ] Test cache functionality

- [ ] **Task 7: Performance Testing** (AC: 7)
  - [ ] Test processing time <2s per post
  - [ ] Test parallel processing of multiple posts
  - [ ] Monitor API latency

---

## Dev Notes

### Previous Story Insights
- Stories from Epic 1 should be complete (infrastructure, database, workers)
- This is the first analysis module of the decision engine

### DeepSeek Client Implementation
[Source: architecture.md#7.2-core-domain-modules]

```typescript
// backend/src/clients/deepseek.ts

import axios from 'axios';
import { logger } from '../utils/logger';

export interface GenerateResult {
  content: string;
  confidence: number;
  usage: {
    prompt_tokens: number;
    completion_tokens: number;
    total_tokens: number;
  };
}

export interface GenerateOptions {
  temperature?: number;
  maxTokens?: number;
}

export class DeepSeekClient {
  private baseUrl = 'https://api.deepseek.com/v1';
  private apiKey: string;

  constructor() {
    this.apiKey = process.env.DEEPSEEK_API_KEY!;
    if (!this.apiKey) {
      throw new Error('DEEPSEEK_API_KEY environment variable is required');
    }
  }

  async generate(prompt: string, options?: GenerateOptions): Promise<GenerateResult> {
    try {
      const response = await axios.post(
        `${this.baseUrl}/chat/completions`,
        {
          model: 'deepseek-reasoner', // DeepSeek R1
          messages: [
            {
              role: 'system',
              content: 'You are a precise text classifier. Respond with structured JSON only.',
            },
            { role: 'user', content: prompt },
          ],
          temperature: options?.temperature ?? 0.3,
          max_tokens: options?.maxTokens ?? 200,
        },
        {
          headers: {
            'Authorization': `Bearer ${this.apiKey}`,
            'Content-Type': 'application/json',
          },
          timeout: 10000, // 10s timeout
        }
      );

      const message = response.data.choices[0].message;
      
      return {
        content: message.content,
        confidence: this.extractConfidence(message),
        usage: response.data.usage,
      };
    } catch (error) {
      logger.error('DeepSeek API call failed', { error });
      throw error;
    }
  }

  private extractConfidence(message: any): number {
    // Extract confidence from response
    // DeepSeek may include reasoning; parse confidence if available
    try {
      const parsed = JSON.parse(message.content);
      return parsed.confidence || 0.85;
    } catch {
      return 0.85; // Default confidence
    }
  }
}
```

### Linguistic Intent Analyzer
```typescript
// backend/src/analysis/signal-1-linguistic.ts

import { DeepSeekClient } from '../clients/deepseek';
import { logger } from '../utils/logger';
import { createHash } from 'crypto';
import NodeCache from 'node-cache';

interface SignalResult {
  score: number;
  confidence: number;
  category: 'high_solution' | 'moderate' | 'low_solution';
  reasoning?: string;
}

const cache = new NodeCache({ stdTTL: 7 * 24 * 60 * 60 }); // 7 days

export class LinguisticIntentAnalyzer {
  private deepseek: DeepSeekClient;

  constructor() {
    this.deepseek = new DeepSeekClient();
  }

  async analyzeLinguisticIntent(content: string): Promise<SignalResult> {
    // Check cache
    const cacheKey = this.getCacheKey(content);
    const cached = cache.get<SignalResult>(cacheKey);
    if (cached) {
      logger.debug('SSS cache hit', { cacheKey });
      return cached;
    }

    try {
      const prompt = this.buildPrompt(content);
      const result = await this.deepseek.generate(prompt, {
        temperature: 0.3,
        maxTokens: 200,
      });

      const parsed = this.parseResponse(result.content);
      
      // Fallback to GPT-4 if confidence too low
      if (result.confidence < 0.85) {
        logger.warn('DeepSeek confidence low, using fallback', {
          confidence: result.confidence,
        });
        return this.fallbackToGPT4(content);
      }

      const signalResult: SignalResult = {
        score: parsed.score,
        confidence: result.confidence,
        category: this.categorize(parsed.score),
        reasoning: parsed.reasoning,
      };

      // Cache result
      cache.set(cacheKey, signalResult);

      return signalResult;
    } catch (error) {
      logger.error('Linguistic intent analysis failed', { error });
      // Default to moderate score on error
      return {
        score: 0.5,
        confidence: 0.0,
        category: 'moderate',
      };
    }
  }

  private buildPrompt(content: string): string {
    return `
Analyze this social media post and determine if the author is genuinely seeking solutions/help or just venting/joking.

POST:
"${content}"

SOLUTION-SEEKING INDICATORS (high score 0.82-1.0):
- Questions asking "what works", "how to fix", "what helps"
- Words: "desperate", "need", "please help", "advice"
- Actionable intent: looking for concrete solutions
Examples:
- "What actually works to stop a hangover headache fast?" â†’ 0.95
- "Need help. This migraine is killing me. What do you guys use?" â†’ 0.90

MODERATE (0.55-0.82):
- Passive complaints with some openness to help
- Mentions symptoms but doesn't explicitly ask for solutions
Examples:
- "Ugh, this hangover is brutal. Anyone else feeling it?" â†’ 0.65
- "My head is pounding and I have a meeting in an hour" â†’ 0.70

LOW SOLUTION-SEEKING (0.0-0.55):
- Pure venting with no questions
- Jokes, memes, sarcasm
- Storytelling, exaggeration
- No indication of wanting help
Examples:
- "Last night was lit but today I'm paying for it lol" â†’ 0.30
- "Hangovers hit different when you're over 30 ðŸ’€" â†’ 0.25

Respond with JSON:
{
  "score": 0.0-1.0,
  "confidence": 0.0-1.0,
  "reasoning": "brief explanation"
}`;
  }

  private parseResponse(content: string): { score: number; reasoning: string } {
    try {
      const parsed = JSON.parse(content);
      return {
        score: Math.max(0, Math.min(1, parsed.score)),
        reasoning: parsed.reasoning || '',
      };
    } catch (error) {
      logger.error('Failed to parse DeepSeek response', { content });
      return { score: 0.5, reasoning: 'Parse error' };
    }
  }

  private categorize(score: number): 'high_solution' | 'moderate' | 'low_solution' {
    if (score >= 0.82) return 'high_solution';
    if (score >= 0.55) return 'moderate';
    return 'low_solution';
  }

  private getCacheKey(content: string): string {
    return createHash('md5').update(content).digest('hex');
  }

  private async fallbackToGPT4(content: string): Promise<SignalResult> {
    // GPT-4 fallback implementation
    // TODO: Implement GPT-4 client if needed
    logger.warn('GPT-4 fallback not implemented, using moderate default');
    return {
      score: 0.5,
      confidence: 0.5,
      category: 'moderate',
    };
  }
}

// Export singleton
export const linguisticAnalyzer = new LinguisticIntentAnalyzer();
export const analyzeLinguisticIntent = (content: string) => 
  linguisticAnalyzer.analyzeLinguisticIntent(content);
```

### Environment Variables
```bash
# DeepSeek API
DEEPSEEK_API_KEY=your_api_key_here

# Optional: GPT-4 fallback
OPENAI_API_KEY=your_openai_key_here
```

### File Structure
```
backend/src/
â”œâ”€â”€ clients/
â”‚   â””â”€â”€ deepseek.ts              # DeepSeek R1 API client
â””â”€â”€ analysis/
    â””â”€â”€ signal-1-linguistic.ts   # SSS analyzer
```

---

## Testing

### Test File Location
- `backend/tests/unit/analysis/signal-1-linguistic.test.ts`
- `backend/tests/integration/clients/deepseek.test.ts`

### Testing Standards
- Mock DeepSeek API responses
- Test all score categories
- Verify cache functionality
- Test error handling

### Story-Specific Testing Requirements
1. 20+ example posts achieve >85% accuracy
2. High solution posts score 0.82+
3. Moderate posts score 0.55-0.82
4. Low solution posts score <0.55
5. Processing time <2 seconds
6. Cache works for duplicate content
7. Error handling defaults to 0.5

---

## Change Log

| Date | Version | Description | Author |
|------|---------|-------------|--------|
| 2024-12-01 | 1.0 | Initial story draft | Bob (SM Agent) |

---

## Dev Agent Record

### Agent Model Used
*To be filled by Dev Agent*

### Debug Log References
*To be filled by Dev Agent*

### Completion Notes List
*To be filled by Dev Agent*

### File List
*To be filled by Dev Agent*

---

## QA Results
*To be filled by QA Agent*

