# Story 2.13: Context Intelligence Engine & Decision Re-evaluation

## Status: Draft

## Story

**As a** the decision engine,
**I want** a dedicated "Context Intelligence Layer" that retrieves deep conversational graphs and re-evaluates decisions,
**so that** I never enter a thread blindfolded and can create "hyper-aware" replies that understand the full history, tone flow, and participant dynamics of the conversation.

## Acceptance Criteria

1. **Context Engine & Gate**
   - Module: `@backend/analysis/context-intel/service.ts`
   - Gate triggers when `decision.score >= 0.65` **or** `power_user === true` **or** `competitor_detected === true` **or** manual override flag.
   - Budget Manager: per-platform call ceilings and token caps with fallback to **Light Mode** (root + parent only) when budgets are exhausted; exposes `context_cost` and `budget_state` in results.

2. **Platform Graph Walkers (Dynamic Depth)**
   - **Twitter/X**: Use `conversation_id`; fetch root + parent chain (max depth 4), top 5 siblings by likes/recency, include author influence (followers, verified) on nodes.
   - **Reddit**: `GET /comments/{article}` depth ≤4; include Submission (title + body), parent chain, top 3 sibling comments by score; capture subreddit mod hints (locked/removed) when present.
   - **Threads**: Fetch thread root + parent chain (max depth 3) + top 5 replies by likes; degrade gracefully to (root + target) when API returns partial data.
   - All walkers normalize timestamps, engagement metrics, author handles/ids, and attach platform to each node.

3. **ConversationGraph & ContextDigest**
   - Graph nodes carry: `id`, `authorId`, `handle`, `influence` (followers/verified), `role` (OP/Target/Sibling), `stance` (support/attack/neutral), `sentiment` (-1..1), `toxicity`, `engagement`, `isTarget`, `depth`.
   - Derived `ContextDigest` includes: conversation summary (≤220 words), tone flow vector, participant roles map, repeated suggestions list, competitor mentions, moderation risk flags, and `promptPayload` list formatted as `[ROLE] @user: "text" (sentiment: x)`.
   - Output type: `ContextResult { graph, digest, promptPack, flags, costs }`.

4. **Token Optimization & Summarization**
   - Normalize raw text to dialogue (strip URLs/mentions, collapse whitespace) and de-duplicate near-identical siblings.
   - If raw context >1500 tokens, compress with `gpt-4o-mini` (or local fast sentiment + extractive summary) to ≤600 tokens; drop low-signal nodes (depth>4 AND engagement < p25) before summarization.
   - Record `tokens_in`, `tokens_out`, and summarization path in `ContextResult`.

5. **Re-Evaluation Logic**
   - Compute `adjustedScore` using context signals: hostility % (drop), answered_by_high_influence (drop), OP-unanswered or clarification request (boost), competitor density (mode → Defensive/Hybrid), mod-lock/NSFW (abort), duplicate advice saturation (drop).
   - Detect stance diversity and “already answered well” (upvotes + OP acknowledgement) to steer toward additive replies or disengage; prefer stance-balanced sibling set over raw like counts.
   - Emit `recommendation` in `{'PROCEED','ADJUST_MODE','ABORT','DEFER'}` with `reason` strings.
   - Run thread-level safety again on the assembled graph; any hard safety hit forces `ABORT`.

6. **Prompt Packaging & Handoff**
   - Provide `ContextPack` for the Reply Generator containing: `compact_dialogue`, `insights`, `strategy_notes` (who to ignore/acknowledge), and `constraints` (char limits, avoid repeating sibling advice).
   - Guarantee prompt pack ≤900 tokens and explicitly notes character budgets for X/Threads.
   - Structured schema: `must_keep` (OP, target, top stance reps, key hostility/competitor signals), `nice_to_have` (extra siblings), `constraints` (char limits, avoid repeats), `strategy` (acknowledge/ignore), `red_flags` (hostility/mod rules/competitors), plus 2–3 evidence bullets to ground the reply.

7. **Caching, Persistence, Observability**
   - Redis cache (TTL 30 min) keyed by `root_id + target_id + platform`; include cache hit/miss in metrics.
   - Persist minimal snapshot (`context_snapshots` table) of digest + promptPack for audit/debug (id referenced on Decision).
   - Metrics emitted: cache hit rate, API calls per platform, token spend, abort reasons, average adjusted delta; unit tests cover gate logic, walker selection, summarization path, and re-evaluation adjustments.

8. **Cost/Value Controls & Adaptation**
   - Tiered modes: Light (root+parent), Standard (chain + sibling representatives), Full (rich siblings + summaries); auto-downgrade to Light on timeout or budget exhaustion.
   - Budget-aware ordering: fetch root/parent first, then highest-value siblings; stop early if expected value < remaining budget.
   - Freshness bias: prefer recent replies; downweight stale siblings in long threads; refresh siblings more frequently than roots in cache.
   - Outcome-linked tuning: track context uplift (adjusted score delta and downstream reply success) by platform/daypart/author tier to auto-tune depth, gate thresholds, and mode selection.

---

## Tasks / Subtasks

- [ ] **Task 1: Core Service Scaffold**
  - [ ] Create `ContextEngine` with `evaluate(decision)` signature
  - [ ] Define `ConversationGraph`, `ContextDigest`, `ContextResult` types
  - [ ] Implement Budget Manager + Redis caching layer

- [ ] **Task 2: Platform Graph Walkers**
  - [ ] `TwitterGraphWalker`: `conversation_id` traversal + sibling scoring
  - [ ] `RedditGraphWalker`: submission + local neighborhood, mod flags
  - [ ] `ThreadsGraphWalker`: parent chain + top replies with graceful degradation

- [ ] **Task 3: Token Optimizer & Summarizer**
  - [ ] Dialogue normalization + de-duplication
  - [ ] Summarization path for >1500 tokens using cheap model
  - [ ] Cost accounting (tokens + API calls)

- [ ] **Task 4: Re-Evaluator & Prompt Packager**
  - [ ] Hostility/competition/duplication scoring to adjust decision
  - [ ] Recommendation generator (`PROCEED/ADJUST/ABORT/DEFER`)
  - [ ] Prompt pack contract for Reply Generator (≤900 tokens)

- [ ] **Task 5: Integration Hooks**
  - [ ] Update Decision Engine contract to accept context snapshot id
  - [ ] Return `ContextResult` reference for Reply Generator consumption

---

## Dev Notes

### Why "Decision Re-evaluation"?
A post might look great in isolation ("I need a cure!").
But in context, maybe 50 people already replied "Drink water", and the OP is angry.
A "blind" bot replies "Try Vita!".
A "hyper-aware" bot sees the saturation and replies: "I see lots of water suggestions, but if you're nauseous, that might be hard. Transdermal patches bypass the stomach..."
This contextual pivot is what makes the bot "Smart".
