# Story 2.7: Post Queue Processor Service

## Status: Draft

## Story

**As a** the system,  
**I want** a service that continuously processes unprocessed posts from the queue,  
**so that** posts detected by the Stream Monitor are analyzed and decisions are made asynchronously.

## Acceptance Criteria

1. Service created at `@backend/services/queue-processor.ts`
2. Service runs on interval (every 30 seconds) querying `posts` WHERE `processed_at IS NULL`
3. For each post:
   - Execute all 4 signals in parallel (Promise.all for speed)
   - Run Safety Protocol check
   - Calculate Decision Score and select mode
   - Write decision to `decisions` table
   - Update post with `processed_at` timestamp
4. **Error handling with retry logic**:
   - Failed posts marked with `error_message` in posts table
   - Retry strategy: Max 3 attempts with exponential backoff (1s → 2s → 4s)
   - Permanent failures (4xx errors): No retry, mark as failed
   - Transient failures (5xx, timeout): Retry with backoff
   - Circuit breaker: After 5 consecutive failures, pause processing for 30s
   - Error tracking: Increment `error_count` field, log to structured logger with request_id
5. Service logs throughput metrics (posts processed per minute)
6. Integration test: Seed queue with 10 posts, verify all processed within 1 minute
7. Service deployed as Docker Compose persistent service with restart policy
8. Dashboard shows queue depth metric (unprocessed posts count)

---

## Tasks / Subtasks

- [ ] **Task 1: Create Queue Processor Service** (AC: 1, 2)
  - [ ] Create `backend/src/services/queue-processor.ts`
  - [ ] Implement QueueProcessor class
  - [ ] Query unprocessed posts (processed_at IS NULL)
  - [ ] Run on 30-second interval
  - [ ] Implement graceful shutdown

- [ ] **Task 2: Integrate Decision Engine** (AC: 3)
  - [ ] For each post, fetch author
  - [ ] Call decisionEngine.analyzePost()
  - [ ] Update post with processed_at timestamp
  - [ ] Handle batch processing efficiently

- [ ] **Task 3: Implement Error Handling** (AC: 4)
  - [ ] Try/catch around each post processing
  - [ ] Increment error_count on failure
  - [ ] Store error_message in posts table
  - [ ] Implement retry logic with exponential backoff
  - [ ] Max 3 retries per post
  - [ ] Mark permanent failures (no more retries)

- [ ] **Task 4: Implement Circuit Breaker** (AC: 4)
  - [ ] Track consecutive failure count
  - [ ] After 5 failures, pause for 30s
  - [ ] Reset on successful processing
  - [ ] Log circuit breaker state changes

- [ ] **Task 5: Add Throughput Metrics** (AC: 5)
  - [ ] Track posts processed per minute
  - [ ] Track average processing time
  - [ ] Track error rate
  - [ ] Log metrics periodically

- [ ] **Task 6: Add to Worker Manager** (AC: 7)
  - [ ] Register QueueProcessor in WorkerManager
  - [ ] Configure restart policy in Docker Compose
  - [ ] Implement graceful shutdown

- [ ] **Task 7: Create Dashboard API** (AC: 8)
  - [ ] Add endpoint GET /api/queue/depth
  - [ ] Return count of unprocessed posts
  - [ ] Return oldest unprocessed post age

- [ ] **Task 8: Write Integration Test** (AC: 6)
  - [ ] Seed 10 test posts
  - [ ] Start queue processor
  - [ ] Verify all processed within 60s
  - [ ] Verify decisions created

---

## Dev Notes

### Previous Story Insights
- Story 1.7 complete (WorkerManager pattern)
- Story 2.5 complete (DecisionEngine)
- This service orchestrates the entire decision flow

### Queue Processor Implementation
```typescript
// backend/src/services/queue-processor.ts

import { prisma } from '../db';
import { decisionEngine } from '../analysis/decision-engine';
import { logger } from '../utils/logger';

export class QueueProcessor {
  private intervalMs = 30 * 1000; // 30 seconds
  private isRunning = false;
  private consecutiveFailures = 0;
  private circuitBreakerOpen = false;
  private metricsInterval: NodeJS.Timeout | null = null;
  private processedCount = 0;
  private lastMetricsReset = Date.now();

  async start(): Promise<void> {
    this.isRunning = true;
    logger.info('Queue Processor starting');

    // Start metrics logging
    this.metricsInterval = setInterval(() => this.logMetrics(), 60 * 1000);

    while (this.isRunning) {
      try {
        // Check circuit breaker
        if (this.circuitBreakerOpen) {
          logger.warn('Circuit breaker open, pausing processing');
          await this.sleep(30000); // 30s pause
          this.circuitBreakerOpen = false;
          this.consecutiveFailures = 0;
          continue;
        }

        await this.processQueue();
        await this.sleep(this.intervalMs);
      } catch (error) {
        logger.error('Queue processing cycle failed', { error });
        await this.sleep(this.intervalMs);
      }
    }
  }

  async stop(): Promise<void> {
    this.isRunning = false;
    if (this.metricsInterval) {
      clearInterval(this.metricsInterval);
    }
    logger.info('Queue Processor stopped');
  }

  private async processQueue(): Promise<void> {
    // Get unprocessed posts
    const posts = await prisma.post.findMany({
      where: { processedAt: null },
      orderBy: { detectedAt: 'asc' },
      take: 50, // Process 50 at a time
      include: { author: true },
    });

    if (posts.length === 0) {
      return;
    }

    logger.info(`Processing ${posts.length} posts from queue`);

    // Process posts in parallel (up to 10 concurrent)
    const batchSize = 10;
    for (let i = 0; i < posts.length; i += batchSize) {
      const batch = posts.slice(i, i + batchSize);
      await Promise.all(batch.map(post => this.processPost(post)));
    }
  }

  private async processPost(post: any): Promise<void> {
    const startTime = Date.now();
    const maxRetries = 3;
    let attempt = 0;

    while (attempt < maxRetries) {
      try {
        // Run decision engine
        await decisionEngine.analyzePost(post, post.author);

        // Mark as processed
        await prisma.post.update({
          where: { id: post.id },
          data: { processedAt: new Date() },
        });

        // Success
        this.consecutiveFailures = 0;
        this.processedCount++;
        
        const duration = Date.now() - startTime;
        logger.debug('Post processed successfully', {
          postId: post.id,
          duration,
          attempt: attempt + 1,
        });

        return;
      } catch (error: any) {
        attempt++;
        
        const isTransient = this.isTransientError(error);
        const shouldRetry = isTransient && attempt < maxRetries;

        logger.error('Post processing failed', {
          postId: post.id,
          attempt,
          error: error.message,
          isTransient,
          willRetry: shouldRetry,
        });

        if (shouldRetry) {
          // Exponential backoff
          const delayMs = Math.pow(2, attempt - 1) * 1000;
          await this.sleep(delayMs);
          continue;
        } else {
          // Permanent failure
          await this.markPostFailed(post.id, error.message, attempt);
          this.consecutiveFailures++;
          
          // Check circuit breaker
          if (this.consecutiveFailures >= 5) {
            this.circuitBreakerOpen = true;
            logger.error('Circuit breaker opened', {
              consecutiveFailures: this.consecutiveFailures,
            });
          }
          
          return;
        }
      }
    }
  }

  private async markPostFailed(
    postId: string,
    errorMessage: string,
    attempts: number
  ): Promise<void> {
    await prisma.post.update({
      where: { id: postId },
      data: {
        processedAt: new Date(), // Mark as processed (failed)
        errorCount: attempts,
        errorMessage: errorMessage.substring(0, 500),
      },
    });
  }

  private isTransientError(error: any): boolean {
    // 5xx errors, timeouts, network errors are transient
    if (error.code === 'ECONNREFUSED' || error.code === 'ETIMEDOUT') {
      return true;
    }
    if (error.status >= 500 && error.status < 600) {
      return true;
    }
    // 4xx errors are permanent
    if (error.status >= 400 && error.status < 500) {
      return false;
    }
    // Default to transient (retry)
    return true;
  }

  private logMetrics(): void {
    const elapsed = (Date.now() - this.lastMetricsReset) / 1000 / 60; // minutes
    const throughput = this.processedCount / elapsed;

    logger.info('Queue Processor metrics', {
      postsProcessed: this.processedCount,
      throughputPerMin: throughput.toFixed(2),
      consecutiveFailures: this.consecutiveFailures,
      circuitBreakerOpen: this.circuitBreakerOpen,
    });

    // Reset counters
    this.processedCount = 0;
    this.lastMetricsReset = Date.now();
  }

  private sleep(ms: number): Promise<void> {
    return new Promise(resolve => setTimeout(resolve, ms));
  }
}

// Export singleton
export const queueProcessor = new QueueProcessor();
```

### Integration with Worker Manager
```typescript
// backend/src/workers/index.ts

import { queueProcessor } from '../services/queue-processor';

// Add to WorkerManager
this.workers.set('queue-processor', {
  worker: queueProcessor,
  running: false,
});
```

### Dashboard API
```typescript
// backend/src/api/routes/queue.ts

import { Hono } from 'hono';
import { prisma } from '../../db';

const queue = new Hono();

queue.get('/depth', async (c) => {
  const unprocessedCount = await prisma.post.count({
    where: { processedAt: null },
  });

  const oldestUnprocessed = await prisma.post.findFirst({
    where: { processedAt: null },
    orderBy: { detectedAt: 'asc' },
  });

  const ageMinutes = oldestUnprocessed
    ? (Date.now() - oldestUnprocessed.detectedAt.getTime()) / 1000 / 60
    : 0;

  return c.json({
    depth: unprocessedCount,
    oldestAgeMinutes: Math.round(ageMinutes),
  });
});

export { queue };
```

### File Structure
```
backend/src/
├── services/
│   └── queue-processor.ts       # THIS STORY
├── workers/
│   └── index.ts                 # WorkerManager (updated)
└── api/
    └── routes/
        └── queue.ts             # Queue depth API
```

---

## Testing

### Test File Location
- `backend/tests/unit/services/queue-processor.test.ts`
- `backend/tests/integration/services/queue-flow.test.ts`

### Testing Standards
- Mock DecisionEngine
- Test retry logic
- Test circuit breaker
- Test error handling

### Story-Specific Testing Requirements
1. 10 posts processed within 60s
2. Retry logic works (3 attempts max)
3. Circuit breaker opens after 5 failures
4. Transient errors trigger retry
5. Permanent errors don't retry
6. Metrics logged correctly
7. Queue depth API returns correct count

---

## Change Log

| Date | Version | Description | Author |
|------|---------|-------------|--------|
| 2024-12-01 | 1.0 | Initial story draft | Bob (SM Agent) |

---

## Dev Agent Record
*To be filled by Dev Agent*

---

## QA Results
*To be filled by QA Agent*

