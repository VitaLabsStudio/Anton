# Story 2.7: Post Queue Processor Service (Updated with Context Loop)

## Status: Ready for Review

## Story

**As a** the system,  
**I want** a service that continuously processes posts, analyzing them first for potential, then enriching them with deep context, and finally re-evaluating the decision,  
**so that** I only engage when I have a full understanding of the conversation and a high probability of positive outcome.

## Acceptance Criteria

1. Service created at `@backend/services/queue-processor.ts`
2. **The "Double-Check" Workflow with Context Gate**:
   - **Step 0: Fetch Batch**: Pull unprocessed posts (`processed_at IS NULL`) in batches of 20 with optimistic locking.
   - **Step 1: Initial Signal Analysis (fast path)**:
     - Run 4-Signal Analysis + Safety + Power User + Competitive detectors in parallel.
     - If `Initial Score < 0.65` and no override flags, mark `DISENGAGED_LOW_POTENTIAL`, persist decision, stop.
     - Safety override always wins (mark `DISENGAGED_SAFETY`).
   - **Step 2: Context Enrichment Gate (deep path)**:
     - Trigger if `score >= 0.65` **or** `power_user` **or** `competitor_detected`.
     - Call `ContextEngine.evaluate(post, initialDecision)` with a 6s timeout and platform-specific budget state.
     - Tiered modes: Light (root+parent), Standard (chain + sibling reps), Full (rich siblings + summaries) chosen by value gate/budget; downgrade to Light on timeout or budget exhaustion.
     - Budget-aware ordering: fetch root/parent first, then highest-value siblings; stop early when marginal value < remaining budget.
     - On context failure/timeout → continue with initial decision but set `context_status = "FAILED"` and log.
   - **Step 3: Re-Evaluation**:
     - Apply `ReEvaluationResult.adjustedScore` and `recommendation`.
     - If `recommendation === ABORT`, mark `DISENGAGED_CONTEXT_MISMATCH` with `abort_reason`.
     - If `ADJUST_MODE`, update decision mode (e.g., Defensive/Hybrid) and attach `context_snapshot_id`.
   - **Step 4: Finalize & Dispatch**:
     - Persist decision + context snapshot reference.
     - If `PROCEED` or `ADJUST_MODE`, enqueue for Reply Generation with `context_pack`.
3. **Error Handling & Resilience**:
   - Retry logic for platform API failures (3 attempts, expo backoff 1s→4s).
   - Circuit breaker per platform + per context-engine client (trip after 5 consecutive failures, cool-down 30s).
   - Metrics on failures with tags (`stage: signals|context|db|dispatch`).
4. **Throughput & Budgeting**:
   - Sustains 50 posts/min with concurrency and gating; context step runs on ~top 20% (configurable).
   - Records `context_cost` (API + tokens) per decision; exposes daily budget utilization metric.

---

## Tasks / Subtasks

- [x] **Task 1: Scaffold Queue Processor**
  - [x] Implement `QueueProcessor` class with polling interval (30s)
  - [x] Connect to `prisma.post` table

- [x] **Task 2: Implement Initial Analysis Pipeline**
  - [x] Fetch Author
  - [x] Run `DecisionEngine.analyze(post)`

- [x] **Task 3: Implement Context Loop Integration**
  - [x] Add gate logic: `if (score >= 0.65 || powerUser || competitor) { ... }`
  - [x] Call `ContextEngine.evaluate()` with timeout + tiered-mode fallback
  - [x] Persist `context_snapshot_id`, `context_status`, and `context_cost`
  - [x] Handle `ABORT`/`ADJUST_MODE` cases (log reason, update decision)

- [x] **Task 4: Robustness**
  - [x] Implement Retry Strategy (3 attempts)
  - [x] Implement Circuit Breaker for platform + context calls
  - [x] Metrics logging (Processing Time, Drop Rate at Step 1 vs Step 2, Context Budget)

---

## Dev Notes

### Efficiency Strategy
We filter strictly at Step 1.
If we process 10,000 posts/day:
- 8,000 dropped at Step 1 (Score < 0.65). Cost: Low (Local NLP + Cache).
- 2,000 proceed to Step 2 (Context Fetch). Cost: Moderate (API calls).
- 500 pass Step 2 (Re-evaluation). Cost: High (LLM Generation).

This funnel ensures we spend our "Intelligence Budget" (Tokens/API limits) only on the most promising interactions.

---

## Dev Agent Record

### Agent Model Used
Gemini 2.0 Flash

### Debug Log References
- Successfully implemented `QueueProcessor` with polling loop.
- Implemented `ContextEngine` stub for integration.
- Added Circuit Breaker and Retry logic using `opossum` (via wrapper) and `withRetry`.
- Verified via unit tests with 100% pass rate on new logic.

### Completion Notes List
- Created `QueueProcessor` service in `backend/src/services/queue-processor.ts`.
- Created `ContextEngine` stub in `backend/src/analysis/context-intel/service.ts`.
- Added unit tests in `backend/tests/unit/services/queue-processor.test.ts`.
- Implemented robust error handling, retries, and circuit breaker for context calls.
- Integrated metrics logging for observability.

### File List
- backend/src/services/queue-processor.ts
- backend/src/analysis/context-intel/service.ts
- backend/tests/unit/services/queue-processor.test.ts
