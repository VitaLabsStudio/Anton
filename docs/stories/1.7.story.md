# Story 1.7: Stream Monitor Worker with Maximum Reach Filtering & Reddit Karma Strategy

## Status: Draft

## Story

**As** the system,  
**I want** a persistent background worker with optimized keyword filtering (RegExp), robust process management (PM2), and safe Reddit interaction gates,  
**so that** we efficiently identify potential customers (1,500-2,500/week) without crashing servers or violating Reddit ToS.

## Acceptance Criteria

1. **Process Management**: Worker managed via `pm2` (ecosystem.config.js) with auto-restart and error logging.
2. **Optimized Keyword Matching** (PERF-001):
   - Uses compiled `RegExp` for O(1) matching of 200+ terms.
   - Pushes filtering to platform APIs (e.g., Twitter OR queries) where possible.
   - Supports 9 categories of keywords.
3. **Idempotency** (DATA-001):
   - Database writes use `upsert` (or equivalent safe logic) to prevent duplicates on restart.
   - Unique constraint on `[platform, platform_post_id]`.
4. **Tier 2: Minimal Spam Filtering** (permissive by default).
5. **Temporal Intelligence**: Polling logic adapts frequency based on time-of-week (e.g., Sunday morning peak).
6. **Safe Reddit Integration** (BUS-001):
   - **NO AUTOMATED KARMA FARMING**.
   - "Karma Gate" implemented: Bot *refuses* to post if karma < threshold (100).
   - Manual karma building process documented.
7. **Monitoring**:
   - Worker logs comprehensive funnel metrics.
   - Graceful degradation for platform failures.

## Tasks / Subtasks

- [ ] **Task 1: Create Keywords Configuration** (AC: 2)
  - [ ] Create `backend/src/config/keywords.json`.
  - [ ] **Implement Full Taxonomy (9 Categories)**:
    - [ ] Category 1: Direct Hangover (e.g., "hungover", "morning after")
    - [ ] Category 2: Physical Symptoms PRIMARY (e.g., "nausea", "splitting headache")
    - [ ] Category 3: Physical Symptoms SECONDARY (e.g., "dehydrated", "shaking")
    - [ ] Category 4: Cognitive/Emotional (e.g., "hangxiety", "regret")
    - [ ] Category 5: Drinking Context (e.g., "binge", "shots")
    - [ ] Category 6: Recovery Intent (e.g., "cure", "help me")
    - [ ] Category 7: Wellness Context (e.g., "hydration", "electrolytes")
    - [ ] Category 8: Slang (e.g., "wasted", "hammered")
    - [ ] Category 9: Meme Language (e.g., "down bad")
  - [ ] Add exclusions array (spam patterns).

- [ ] **Task 2: Create Keyword Matcher (RegExp Optimized)** (AC: 2)
  - [ ] Create `backend/src/workers/keyword-matcher.ts`.
  - [ ] Implement `KeywordMatcher` class.
  - [ ] **Optimization**: Flatten all keywords into a single pre-compiled `RegExp` (O(1) lookup) instead of looping.
  - [ ] Implement `getMatches(text)` to return specific matched categories.

- [ ] **Task 3: Create Spam Filter** (AC: 4)
  - [ ] Create `backend/src/workers/spam-filter.ts`.
  - [ ] Implement regex-based filtering:
    - [ ] Media: "The Hangover" (movie/soundtrack)
    - [ ] Crypto: "Bitcoin", "Airdrop"
    - [ ] Brand/Influencer: Verified + >50k followers (if accessible via API)

- [ ] **Task 4: Create Temporal Intelligence** (AC: 5)
  - [ ] Create `backend/src/workers/temporal-multiplier.ts`.
  - [ ] Implement `getTemporalMultiplier()` logic:
    - [ ] Sunday 6-11am: 3x frequency
    - [ ] Saturday 6-11am: 2x frequency
    - [ ] Friday/Saturday Night: 1.5x frequency
    - [ ] Default: 1x

- [ ] **Task 5: Create Platform Monitors (Optimized)** (AC: 2, 3)
  - [ ] Create `backend/src/platforms/twitter/monitor.ts`: Use API-level OR queries to reduce data fetch.
  - [ ] Create `backend/src/platforms/reddit/monitor.ts`: Monitor target subreddits (r/hangover, r/drunk).
  - [ ] Create `backend/src/platforms/threads/monitor.ts`: Hashtag search.
  - [ ] Ensure monitors extract standardized `DetectedPost` objects.

- [ ] **Task 6: Create Stream Monitor Worker** (AC: 3, 7)
  - [ ] Create `backend/src/workers/stream-monitor.ts`.
  - [ ] Initialize `KeywordMatcher` and monitors.
  - [ ] Implement polling loop with `getTemporalMultiplier`.
  - [ ] **Process Flow**: Fetch -> Match(RegExp) -> SpamFilter -> Upsert DB.
  - [ ] **Crucial**: Use `prisma.post.upsert` to prevent duplicates (DATA-001).

- [ ] **Task 7: Implement Reddit Karma Gate** (AC: 6)
  - [ ] Create `backend/src/workers/guards/karma-gate.ts`.
  - [ ] Implement `checkKarma(client)`:
    - [ ] Return `false` if karma < 100.
    - [ ] Return `false` if account age < 30 days.
  - [ ] Integrate check into `stream-monitor.ts` (skip reddit actions if check fails).
  - [ ] Create `docs/manuals/reddit-karma.md` explaining the manual engagement strategy.

- [ ] **Task 8: Configure Process Management (PM2)** (AC: 1)
  - [ ] Install `pm2`.
  - [ ] Create `ecosystem.config.js` at project root.
  - [ ] Configure: 1 instance, auto-restart, memory limit (1GB), log paths.
  - [ ] Add npm scripts: `npm run worker:start`, `npm run worker:stop`.

- [ ] **Task 9: Metrics & Tests**
  - [ ] Log funnel metrics (Scanned vs Matched vs Saved).
  - [ ] Test `KeywordMatcher` with large text corpus (ensure performance).
  - [ ] Test `upsert` logic prevents duplicates.

---

## Dev Notes

### Risk Mitigation Strategies
[Source: QA Risk Assessment 1.7-risk-20251202.md]

**CRITICAL: Story 1.7 has 3 CRITICAL RISKS that require immediate architectural redesign.**

#### CRITICAL RISK: Inefficient Keyword Matching (PERF-001)
**Solution**: Use compiled Regular Expression (single pass).
```typescript
// backend/src/workers/keyword-matcher.ts
export class KeywordMatcher {
  private keywordRegex: RegExp;
  constructor(keywordConfig: KeywordConfig) {
    const allTerms = Object.values(keywordConfig.categories).flatMap(cat => cat.terms);
    const escapedTerms = allTerms.map(term => term.replace(/[.*+?^${}()|[\]/g, '\$&'));
    this.keywordRegex = new RegExp(`\b(${escapedTerms.join('|')})\b`, 'i');
  }
  matches(content: string): boolean { return this.keywordRegex.test(content); }
}
```

#### CRITICAL RISK: Worker Manager Over-Simplified (TECH-001)
**Solution**: Use `pm2` (ecosystem.config.js).
```javascript
module.exports = {
  apps: [{
    name: 'antone-worker',
    script: 'dist/workers/stream-monitor.js',
    instances: 1,
    autorestart: true,
    max_memory_restart: '1G',
  }],
};
```

#### CRITICAL RISK: Reddit Karma Strategy is Risky (BUS-001)
**Solution**: **NO AUTOMATION for karma building**.
Implement `KarmaGate`. If karma < 100, Log warning and SKIP posting. Manual intervention required.

#### HIGH RISK: Data Duplication (DATA-001)
**Solution**: Use `prisma.post.upsert`.

### File Structure
```
backend/src/
├── config/
│   └── keywords.json
├── workers/
│   ├── stream-monitor.ts
│   ├── keyword-matcher.ts       # NEW: Regex matcher
│   ├── spam-filter.ts
│   ├── temporal-multiplier.ts
│   └── guards/
│       └── karma-gate.ts        # NEW: Safety check
```
ecosystem.config.js              # NEW: PM2 config

---

## QA Results
*To be filled by QA Agent*
