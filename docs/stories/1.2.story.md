# Story 1.2: Docker Compose Infrastructure Setup

## Status: Draft

## Story

**As a** developer,  
**I want** Docker Compose configuration for all services with proper networking and persistence,  
**so that** the application can run reliably on self-hosted infrastructure with consistent environments.

## Acceptance Criteria

1. `docker-compose.yml` created in repo root with services: backend-api, backend-worker, dashboard, postgres, cloudflared
2. Dockerfile created for Node.js services with multi-stage build using **Node.js 24-alpine** base image:
   - Stage 1 (base): Node 24-alpine + pnpm 10.x via corepack
   - Stage 2 (deps): Install dependencies with frozen lockfile
   - Stage 3 (builder): Build TypeScript to JavaScript
   - Stage 4 (production): Copy dist + node_modules, expose port 3001, non-root user
   - Development target: Hot reload support
   - Production target: Optimized, minimal layers, security hardened
3. PostgreSQL service configured with specific version and persistent volume:
   - Image: `postgres:17-alpine` (latest stable, 30% faster JSON operations)
   - Persistent volume: `postgres_data` mounted to `/var/lib/postgresql/data`
   - Environment: POSTGRES_USER, POSTGRES_PASSWORD, POSTGRES_DB
   - Storage: 1TB available on host machine
   - Health check: `pg_isready -U antone` every 10s
   - Resource allocation: 8-16GB RAM for PostgreSQL (configurable based on workload)
   - Host specs: 32GB RAM total, Intel i5 6-core, 1TB SSD
4. Environment variables defined in `.env.example` (template for `.env`)
5. Health checks configured for all services with specific intervals:
   - PostgreSQL: `pg_isready -U antone` every 10s, timeout 5s, retries 5
   - Backend API: `curl -f http://localhost:3001/health` every 30s, timeout 10s, retries 3
   - Restart policy: `unless-stopped` for all services
6. Network configuration: Internal network for service communication, exposed ports for dashboard
7. Successful deployment locally with `docker-compose up -d`
8. All services healthy and communicating (postgres accessible from backend)
9. Data persists across container restarts (test with `docker-compose down && docker-compose up`)
10. **Cloudflare Tunnel service** configured:
    - Service: `cloudflared` with latest image
    - Command: `tunnel run`
    - Environment: `TUNNEL_TOKEN` from `.env`
    - Purpose: Secure remote access to dashboard without port forwarding
    - Configuration: `docker/cloudflared/config.yml` with ingress rules for dashboard and API
11. **Environment-specific compose files** created:
    - `docker-compose.yml`: Base configuration
    - `docker-compose.dev.yml`: Development overrides (hot reload, debug ports)
    - `docker-compose.prod.yml`: Production optimizations (resource limits, security)
    - Usage: `docker-compose -f docker-compose.yml -f docker-compose.dev.yml up`
12. **Backup Strategy** configured for disaster recovery:
    - Schedule: Automated daily backups at 2:00 AM local time
    - Destination: Backblaze B2 cloud storage (free 10GB tier)
    - Retention: 7-day rolling backups, monthly snapshots kept for 1 year
    - RTO (Recovery Time Objective): 4 hours from backup to operational
    - RPO (Recovery Point Objective): 24 hours maximum data loss
    - Backup verification: Weekly restore tests to local staging environment
    - Implementation: Script at `scripts/backup-db.sh` with cron scheduling

---

## Tasks / Subtasks

- [ ] **Task 1: Create Base Docker Compose File** (AC: 1, 6, DATA-001)
  - [ ] Create `docker/docker-compose.yml` with all services defined
  - [ ] Configure `antone-network` bridge network
  - [ ] Define `postgres_data` volume as EXTERNAL to prevent accidental deletion
  - [ ] Create `docker/volumes.yml` with named postgres_data volume
  - [ ] Set service dependencies with `service_healthy` conditions

- [ ] **Task 2: Create Backend Dockerfile** (AC: 2, TECH-001, SEC-001, PERF-001)
  - [ ] Create `backend/Dockerfile` with optimized multi-stage build (see Dev Notes TECH-001)
  - [ ] Stage 1: Base with Node 24-alpine + pnpm via corepack
  - [ ] Stage 2: Dependencies with `pnpm install --frozen-lockfile --prod`
  - [ ] Stage 3: Builder using `pnpm --filter backend build`
  - [ ] Stage 4: Production with minimal layers, non-root user (antone:nodejs)
  - [ ] Ensure optimal layer caching (deps before source code)
  - [ ] Create `.dockerignore` to exclude secrets and dev artifacts

- [ ] **Task 3: Create Dashboard Dockerfile** (AC: 2)
  - [ ] Create `dashboard/Dockerfile` with multi-stage build
  - [ ] Configure for Next.js 16 production build
  - [ ] Set `NEXT_PUBLIC_API_URL` environment variable
  - [ ] Expose port 3000

- [ ] **Task 4: Configure PostgreSQL Service** (AC: 3, 5, OPS-001)
  - [ ] Use `postgres:17-alpine` image
  - [ ] Mount `postgres_data` external volume
  - [ ] Configure environment variables from .env
  - [ ] Add hardened health check with start_period: 15s (see Dev Notes OPS-001)

- [ ] **Task 5: Configure Backend API Service** (AC: 5, OPS-001)
  - [ ] Build from `backend/Dockerfile` with production target
  - [ ] Set DATABASE_URL environment variable
  - [ ] Expose port 3001
  - [ ] Add hardened health check using wget with start_period: 30s (see Dev Notes OPS-001)
  - [ ] Depend on postgres with condition `service_healthy`
  - [ ] Inject secrets via env_file, not build args

- [ ] **Task 6: Configure Backend Worker Service** (AC: 1)
  - [ ] Build from `backend/Dockerfile` with production target
  - [ ] Override command to `node dist/workers/index.js`
  - [ ] No exposed ports (internal only)
  - [ ] Depend on postgres and backend-api

- [ ] **Task 7: Configure Dashboard Service** (AC: 1)
  - [ ] Build from `dashboard/Dockerfile`
  - [ ] Expose port 3000
  - [ ] Set NEXT_PUBLIC_API_URL to backend-api

- [ ] **Task 8: Configure Cloudflared Service** (AC: 10)
  - [ ] Use `cloudflare/cloudflared:latest` image
  - [ ] Command: `tunnel run`
  - [ ] Environment: TUNNEL_TOKEN from .env
  - [ ] Create `docker/cloudflared/config.yml` with ingress rules

- [ ] **Task 9: Create Environment Template** (AC: 4)
  - [ ] Create `.env.example` with all required variables
  - [ ] Include PostgreSQL credentials
  - [ ] Include platform API keys (placeholders)
  - [ ] Include Cloudflare tunnel token
  - [ ] Add comprehensive comments explaining each variable

- [ ] **Task 10: Create Development Override File** (AC: 11)
  - [ ] Create `docker/docker-compose.dev.yml`
  - [ ] Enable hot reload for backend (mount source code)
  - [ ] Expose debug ports (9229 for Node inspector)
  - [ ] Use development Dockerfile target

- [ ] **Task 11: Create Production Override File** (AC: 11)
  - [ ] Create `docker/docker-compose.prod.yml`
  - [ ] Add resource limits (memory, CPU)
  - [ ] Enable security hardening
  - [ ] Configure log rotation

- [ ] **Task 12: Create Backup Script** (AC: 12)
  - [ ] Create `scripts/backup-db.sh`
  - [ ] Use `pg_dump` for database backup
  - [ ] Compress backup with gzip
  - [ ] Upload to Backblaze B2 (or local backup if B2 not configured)
  - [ ] Implement 7-day rolling retention

- [ ] **Task 13: Create Restore Script** (AC: 12)
  - [ ] Create `scripts/restore-db.sh`
  - [ ] Download backup from B2 or local
  - [ ] Decompress and restore with `pg_restore`
  - [ ] Verify restoration with health check

- [ ] **Task 14: Create Docker Verification Script** (OPS-001 Mitigation)
  - [ ] Create `scripts/verify-docker.sh` with comprehensive checks
  - [ ] Test service health check verification
  - [ ] Test postgres connectivity
  - [ ] Test data persistence across restarts
  - [ ] Make script executable: `chmod +x scripts/verify-docker.sh`

- [ ] **Task 15: Create Docker Build Test Script** (TECH-001 Mitigation)
  - [ ] Create `scripts/test-docker-build.sh`
  - [ ] Test backend image builds successfully
  - [ ] Test image can start and run
  - [ ] Verify cleanup after test
  - [ ] Make script executable: `chmod +x scripts/test-docker-build.sh`

- [ ] **Task 16: Create Docker Troubleshooting Guide** (OPS-001 Mitigation)
  - [ ] Create `docs/DOCKER_TROUBLESHOOTING.md`
  - [ ] Document: Services fail to start
  - [ ] Document: Health checks failing
  - [ ] Document: Services can't communicate
  - [ ] Document: Data not persisting
  - [ ] Document: Permission denied errors
  - [ ] Add link to troubleshooting in main README

- [ ] **Task 17: Create .dockerignore Files** (TECH-001, SEC-001 Mitigation)
  - [ ] Create root `.dockerignore` with secret exclusions (see Dev Notes SEC-001)
  - [ ] Create `backend/.dockerignore`
  - [ ] Create `dashboard/.dockerignore`
  - [ ] Exclude: node_modules, dist, coverage, .env, .env.*, test files, .git, .vscode

- [ ] **Task 18: Enhance Backend for Docker Health Checks** (OPS-001 Mitigation)
  - [ ] CRITICAL: Backend MUST bind to 0.0.0.0, not 127.0.0.1 (see Dev Notes OPS-001)
  - [ ] Add startup logging with emoji indicators
  - [ ] Create `/health` endpoint that returns 200 OK
  - [ ] Log health check endpoint URL on startup

- [ ] **Task 19: Create Safety Wrapper Script** (DATA-001 Mitigation)
  - [ ] Create `scripts/dev-ctl.sh` with dangerous command interception (see Dev Notes DATA-001)
  - [ ] Intercept `down -v` command with confirmation prompt
  - [ ] Make script executable: `chmod +x scripts/dev-ctl.sh`
  - [ ] Update README to use `scripts/dev-ctl.sh` instead of raw docker-compose

- [ ] **Task 19a: Update Docker Compose with Enhanced Health Checks** (OPS-001 Mitigation)
  - [ ] Add start_period to all health checks (postgres: 15s, backend-api: 30s)
  - [ ] Use wget instead of curl for Alpine compatibility
  - [ ] Add clear depends_on conditions (service_healthy)
  - [ ] Test health check commands manually before deployment

- [ ] **Task 20: Test Full Deployment** (AC: 7, 8, 9, ALL RISKS)
  - [ ] Run `scripts/test-docker-build.sh` to verify builds
  - [ ] Copy `.env.example` to `.env` and configure
  - [ ] Run `docker-compose up -d` from docker/ directory
  - [ ] Run `scripts/verify-docker.sh` to verify deployment
  - [ ] Manually test postgres connectivity: `docker-compose exec postgres psql -U antone`
  - [ ] Manually test API: `curl http://localhost:3001/health`
  - [ ] Test data persistence: `docker-compose down && docker-compose up -d`
  - [ ] Document any issues encountered in troubleshooting guide

---

## Dev Notes

### Previous Story Insights
Story 1.1 must be completed first - this story depends on the monorepo structure and package.json files created in 1.1.

### Risk Mitigation Strategies
[Source: QA Risk Assessment 1.2-risk-20251202.md - Enhanced]

**CRITICAL: Story 1.2 has 2 CRITICAL risks, 3 HIGH risks, and 3 MEDIUM risks. Docker infrastructure is the most failure-prone and dangerous part of the project. These mitigation strategies are MANDATORY.**

**Risk Summary**:
- **CRITICAL (Score 9)**: 2 risks
  - DATA-001: Irreversible Data Loss with `docker-compose down -v`
  - OPS-001: Docker Compose Deployment & Health Check Failures
- **HIGH (Score 6-8)**: 3 risks
  - TECH-001: Monorepo Dockerfile Build Failures
  - SEC-001: Leaking Secrets into Docker Image Layers
  - PERF-001: Inefficient Docker Layer Caching
- **MEDIUM (Score 4-5)**: 3 risks
  - CONFIG-001, TECH-002, OPS-003

---

#### CRITICAL RISK: Irreversible Data Loss (DATA-001) - Priority: CRITICAL (Score 9)
**Problem**: A developer running `docker-compose down -v` will instantly and irreversibly delete the entire PostgreSQL database. This is the single most destructive potential error.

**Mitigation & Implementation**:
1. **Use External Volumes with Warnings**: Switch from default Docker volumes to an "external" volume defined outside the main compose file. This makes accidental deletion harder.
   * **Action**: Create a separate `docker/volumes.yml` file:
     ```yaml
     # docker/volumes.yml
     volumes:
       postgres_data:
         name: antone_postgres_data # Explicitly name the volume
     ```
   * **Action**: Update `docker/docker-compose.yml` to use the external volume:
     ```yaml
     # docker/docker-compose.yml
     services:
       postgres:
         # ...
         volumes:
           - postgres_data:/var/lib/postgresql/data
     volumes:
       postgres_data:
         external: true # This prevents 'down -v' from deleting it
     ```
2. **Create a Safety Wrapper Script**: Create a wrapper script `dev-ctl.sh` (Developer Control) as the primary interface for Docker commands. This script can intercept dangerous commands and force confirmation.
   * **Action**: Create `scripts/dev-ctl.sh`:
     ```bash
     #!/bin/bash
     set -euo pipefail

     COMMAND="$1"
     shift

     # Block dangerous commands
     if [[ "$COMMAND" == "down" && ( "$*" == "-v" || "$*" == "--volumes" ) ]]; then
       echo "üö® CRITICAL: You are attempting to delete all Docker volumes, including the database."
       read -p "Are you sure? This cannot be undone. (y/N): " -r REPLY
       if [[ ! "$REPLY" =~ ^[yY]$ ]]; then
         echo "Aborted."
         exit 1
       fi
     fi

     echo "üöÄ Executing: docker-compose -f docker/docker-compose.yml -f docker/docker-compose.dev.yml $COMMAND $@"
     docker-compose -f docker/docker-compose.yml -f docker/docker-compose.dev.yml "$COMMAND" "$@"
     ```
   * **Action**: Make script executable: `chmod +x scripts/dev-ctl.sh`
   * **Action**: Update `README.md` to instruct developers to use `scripts/dev-ctl.sh up` and `scripts/dev-ctl.sh down` instead of raw `docker-compose`.

#### CRITICAL RISK: Docker Compose Deployment & Health Check Failures (OPS-001) - Priority: CRITICAL (Score 9)

**Problem**: Multi-service Docker setups with dependencies, health checks, and networking are highly prone to failures. Common issues include services starting in wrong order, health checks timing out, network misconfiguration, volume permission issues, and environment variable errors.

**Mitigation & Implementation**:
1. **Harden Health Checks**: Use more resilient health check commands and add `start_period` to give services time to initialize before the first check.
   * **Action**: Update `docker/docker-compose.yml` health checks:
     ```yaml
     # postgres service
     healthcheck:
       test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER:-antone}"]
       interval: 10s
       timeout: 5s
       retries: 5
       start_period: 15s # Give Postgres time to initialize

     # backend-api service
     healthcheck:
       # Use wget (pre-installed on alpine) instead of curl
       test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:3001/health"]
       interval: 20s
       timeout: 10s
       retries: 3
       start_period: 30s # Give Node.js app time to build and start
     ```
2. **Ensure Correct App Binding**: Node.js applications in Docker often mistakenly bind to `127.0.0.1`, making them unreachable from other containers or the health check.
   * **Action**: The backend server **MUST** bind to `0.0.0.0`. Add this to the backend implementation:
     ```typescript
     // backend/src/server.ts (or index.ts)
     serve({
       fetch: app.fetch,
       hostname: '0.0.0.0', // CRITICAL: Must be 0.0.0.0 to be reachable in Docker
       port: 3001,
     });
     ```
3. **Comprehensive Verification Script**: Create automated test that validates entire deployment
4. **Detailed Troubleshooting Guide**: Document every common failure scenario

**Implementation Requirements**:

**Create `scripts/verify-docker.sh`**:
```bash
#!/bin/bash
set -e

echo "üê≥ Verifying Docker Compose deployment..."

# Check Docker daemon
if ! docker info > /dev/null 2>&1; then
  echo "‚ùå Docker daemon not running"
  exit 1
fi

# Start services
echo "üì¶ Starting services..."
docker-compose -f docker/docker-compose.yml up -d

# Wait for health checks
echo "‚è≥ Waiting for services to become healthy..."
MAX_WAIT=120
ELAPSED=0
while [ $ELAPSED -lt $MAX_WAIT ]; do
  HEALTHY=$(docker-compose -f docker/docker-compose.yml ps | grep healthy | wc -l)
  if [ "$HEALTHY" -ge 2 ]; then
    echo "‚úÖ All services healthy"
    break
  fi
  sleep 5
  ELAPSED=$((ELAPSED + 5))
done

if [ $ELAPSED -ge $MAX_WAIT ]; then
  echo "‚ùå Services failed to become healthy within ${MAX_WAIT}s"
  docker-compose -f docker/docker-compose.yml ps
  docker-compose -f docker/docker-compose.yml logs --tail=50
  exit 1
fi

# Test postgres connectivity
echo "üîå Testing PostgreSQL connection..."
docker-compose -f docker/docker-compose.yml exec -T postgres \
  psql -U antone -c "SELECT 1" > /dev/null || {
  echo "‚ùå PostgreSQL connection failed"
  exit 1
}

# Test backend API health endpoint
echo "üîå Testing Backend API..."
curl -f http://localhost:3001/health || {
  echo "‚ùå Backend API health check failed"
  exit 1
}

# Test data persistence
echo "üíæ Testing data persistence..."
docker-compose -f docker/docker-compose.yml down
docker-compose -f docker/docker-compose.yml up -d
# Wait for postgres to be healthy again
sleep 10

echo "‚úÖ Docker deployment verification complete"
```

**Create `docs/DOCKER_TROUBLESHOOTING.md`**:
```markdown
# Docker Troubleshooting Guide

## Common Issues and Solutions

### Issue: Services fail to start

**Symptoms**: `docker-compose up -d` exits with error

**Diagnosis**:
```bash
docker-compose logs <service-name>
docker-compose ps  # Check status
```

**Common Causes**:
1. Port already in use (3000, 3001, 5432)
   - Solution: `lsof -i :3001` then kill process or change port
2. Environment file missing
   - Solution: Copy `.env.example` to `.env` and fill values
3. Build context issues
   - Solution: `docker-compose build --no-cache`

### Issue: Health checks failing

**Symptoms**: Container shows "unhealthy" status

**Diagnosis**:
```bash
docker inspect <container-name> | grep -A 10 Health
docker logs <container-name> --tail 100
```

**Solutions**:
- PostgreSQL: Ensure POSTGRES_USER matches health check command
- Backend API: Check if app is listening on 0.0.0.0, not 127.0.0.1
- Increase health check intervals in compose file

### Issue: Services can't communicate

**Symptoms**: Backend can't connect to postgres

**Diagnosis**:
```bash
docker-compose exec backend-api ping postgres
docker network ls
docker network inspect antone-network
```

**Solutions**:
- Ensure all services on same network
- Use service names (postgres), not localhost
- Check DATABASE_URL uses service name: postgresql://user:pass@postgres:5432/db

### Issue: Data not persisting

**Symptoms**: Database empty after restart

**Diagnosis**:
```bash
docker volume ls
docker volume inspect postgres_data
```

**Solutions**:
- Verify volume mounted correctly in compose file
- Check volume path matches Postgres data directory
- Don't use `docker-compose down -v` (removes volumes)

### Issue: Permission denied errors

**Symptoms**: Container can't write to volume

**Solutions**:
- Check volume permissions: `docker-compose exec postgres ls -la /var/lib/postgresql/data`
- Ensure non-root user UID matches volume owner
- May need to chown volume on host
```

**Add to README.md** (Docker section):
```markdown
## Docker Deployment

### Quick Start
```bash
# Copy environment template
cp .env.example .env
# Edit .env with your values

# Start all services
docker-compose -f docker/docker-compose.yml -f docker/docker-compose.dev.yml up -d

# Verify deployment
./scripts/verify-docker.sh

# View logs
docker-compose logs -f backend-api
```

### Troubleshooting
See [DOCKER_TROUBLESHOOTING.md](docs/DOCKER_TROUBLESHOOTING.md) for common issues.

### Emergency Commands
```bash
# Stop all services
docker-compose down

# Rebuild from scratch (preserves data)
docker-compose build --no-cache
docker-compose up -d

# Full reset (WARNING: deletes data)
docker-compose down -v
docker-compose up -d
```
```

#### HIGH RISK: Monorepo Dockerfile Build Failures (TECH-001) - Priority: HIGH (Score 6)
**Problem**: Building a `pnpm` monorepo inside Docker is notoriously difficult. The build context, workspace dependencies, and `pnpm-lock.yaml` must be handled perfectly or builds will fail in subtle ways.

**Mitigation & Implementation**:
1. **Create a Production-Grade, Optimized `Dockerfile`**: The `Dockerfile` must correctly copy all necessary `package.json` files, the lockfile, and source code in the right order to leverage layer caching and ensure `pnpm` can resolve the workspace.
   * **Action**: Use this hardened version as the **correct** way to build a pnpm monorepo in Docker:

     ```dockerfile
     # backend/Dockerfile
     # --- Base Stage ---
     FROM node:24-alpine AS base
     WORKDIR /app
     RUN corepack enable && corepack prepare pnpm@10.0.0 --activate

     # --- Dependencies Stage ---
     FROM base AS deps
     # Copy ALL package.json files from the workspace
     COPY package.json pnpm-lock.yaml ./ 
     COPY backend/package.json ./backend/
     COPY shared/package.json ./shared/
     COPY database/package.json ./database/
     # Install ALL dependencies. Using --frozen-lockfile is a best practice.
     RUN pnpm install --frozen-lockfile --prod

     # --- Build Stage ---
     FROM base AS builder
     # Copy source code and dependencies
     COPY --from=deps /app/node_modules ./node_modules
     COPY --from=deps /app/backend/node_modules ./backend/node_modules
     COPY . .
     # Build the specific workspace package
     RUN pnpm --filter backend build

     # --- Production Stage ---
     FROM base AS production
     ENV NODE_ENV=production
     WORKDIR /app
     # Create a non-root user for security
     RUN addgroup --system --gid 1001 nodejs && adduser --system --uid 1001 antone
     # Copy only production artifacts
     COPY --from=deps /app/node_modules ./node_modules
     COPY --from=deps /app/backend/node_modules ./backend/node_modules
     COPY --from=builder /app/backend/dist ./backend/dist
     COPY --from=builder /app/backend/package.json ./backend/package.json
     USER antone
     EXPOSE 3001
     CMD ["node", "backend/dist/index.js"]
     ```

#### HIGH RISK: Leaking Secrets into Docker Image Layers (SEC-001) - Priority: HIGH (Score 6)
**Problem**: Using `ARG` or copying `.env` files into a Docker image can permanently bake secrets into an image layer, which is a major security vulnerability.

**Mitigation & Implementation**:
1. **Use `.dockerignore` Religiously**: Explicitly ignore all secret files, environment files, and local development artifacts.
   * **Action**: Create/update `.dockerignore` in the project root:
     ```
     # .dockerignore
     .env
     .env.*
     !.env.example

     node_modules
     dist
     .next
     coverage
     
     .DS_Store
     *.log
     
     .git
     .vscode
     ```
2. **Use Runtime Environment Variables**: Secrets must only be passed to the container at runtime, not build time.
   * **Action**: The `docker-compose.yml` file must use the `env_file` or `environment` properties to inject secrets.
     ```yaml
     # docker-compose.yml
     services:
       backend-api:
         env_file:
           - .env # Injects secrets at runtime
     ```

#### HIGH RISK: Inefficient Docker Layer Caching (PERF-001) - Priority: HIGH (Score 6)
**Problem**: A poorly structured `Dockerfile` will bust the layer cache on every code change, making builds painfully slow and discouraging developers from using Docker for local dev.

**Mitigation & Implementation**:
1. **Structure Dockerfile for Caching**: The order of `COPY` and `RUN` commands is critical. Install dependencies *before* copying source code.
   * **Action**: The provided production-grade `Dockerfile` (under TECH-001) is already structured for optimal caching. The key is that `COPY . .` (which copies source code) happens *after* `pnpm install`. A change to a single source file will not cause a full dependency re-install.
   * **Action**: Ensure the final `Dockerfile` follows this pattern with dependencies installed before source code is copied.


### Docker Compose Configuration
[Source: architecture.md#11-infrastructure-deployment]

```yaml
# docker/docker-compose.yml
version: '3.8'

services:
  postgres:
    image: postgres:17-alpine
    container_name: antone-postgres
    environment:
      POSTGRES_USER: ${POSTGRES_USER:-antone}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: ${POSTGRES_DB:-antone}
    volumes:
      - postgres_data:/var/lib/postgresql/data
    ports:
      - "5432:5432"
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U antone"]
      interval: 10s
      timeout: 5s
      retries: 5
    restart: unless-stopped
    networks:
      - antone-network

  backend-api:
    build:
      context: ../backend
      dockerfile: Dockerfile
      target: production
    container_name: antone-backend-api
    environment:
      NODE_ENV: production
      DATABASE_URL: postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres:5432/${POSTGRES_DB}
    env_file:
      - ../.env
    ports:
      - "3001:3001"
    depends_on:
      postgres:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3001/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    restart: unless-stopped
    networks:
      - antone-network

  backend-worker:
    build:
      context: ../backend
      dockerfile: Dockerfile
      target: production
    container_name: antone-backend-worker
    command: ["node", "dist/workers/index.js"]
    environment:
      NODE_ENV: production
      DATABASE_URL: postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres:5432/${POSTGRES_DB}
    env_file:
      - ../.env
    depends_on:
      postgres:
        condition: service_healthy
      backend-api:
        condition: service_healthy
    restart: unless-stopped
    networks:
      - antone-network

  dashboard:
    build:
      context: ../dashboard
      dockerfile: Dockerfile
    container_name: antone-dashboard
    environment:
      NEXT_PUBLIC_API_URL: http://backend-api:3001
    ports:
      - "3000:3000"
    depends_on:
      - backend-api
    restart: unless-stopped
    networks:
      - antone-network

  cloudflared:
    image: cloudflare/cloudflared:latest
    container_name: antone-cloudflared
    command: tunnel run
    environment:
      TUNNEL_TOKEN: ${CLOUDFLARE_TUNNEL_TOKEN}
    restart: unless-stopped
    networks:
      - antone-network

volumes:
  postgres_data:
    driver: local

networks:
  antone-network:
    driver: bridge
```

### Backend Dockerfile
[Source: architecture.md#11.2-dockerfile-backend]

```dockerfile
# backend/Dockerfile

FROM node:24-alpine AS base
WORKDIR /app
RUN corepack enable && corepack prepare pnpm@10.0.0 --activate

# Dependencies stage
FROM base AS deps
COPY package.json pnpm-lock.yaml ./
RUN pnpm install --frozen-lockfile

# Build stage
FROM base AS builder
COPY --from=deps /app/node_modules ./node_modules
COPY . .
RUN pnpm build

# Production stage
FROM base AS production
ENV NODE_ENV=production
RUN addgroup --system --gid 1001 nodejs && \
    adduser --system --uid 1001 antone
COPY --from=builder /app/dist ./dist
COPY --from=builder /app/node_modules ./node_modules
COPY package.json ./
USER antone
EXPOSE 3001
CMD ["node", "dist/index.js"]
```

### Cloudflare Tunnel Configuration
[Source: architecture.md#11.3-cloudflare-tunnel-configuration]

```yaml
# docker/cloudflared/config.yml
tunnel: antone-tunnel
credentials-file: /etc/cloudflared/credentials.json

ingress:
  - hostname: antone.yourdomain.com
    service: http://dashboard:3000
  - hostname: api.antone.yourdomain.com
    service: http://backend-api:3001
  - service: http_status:404
```

### Environment Variables Template
[Source: architecture.md#10.2-secrets-management]

```bash
# .env.example

# PostgreSQL Configuration
POSTGRES_USER=antone
POSTGRES_PASSWORD=your_secure_password_here
POSTGRES_DB=antone

# Platform API Keys (Twitter)
TWITTER_API_KEY=
TWITTER_API_SECRET=
TWITTER_ACCESS_TOKEN=
TWITTER_ACCESS_SECRET=
TWITTER_BEARER_TOKEN=

# Platform API Keys (Reddit)
REDDIT_CLIENT_ID=
REDDIT_CLIENT_SECRET=
REDDIT_REFRESH_TOKEN=

# Platform API Keys (Threads)
THREADS_ACCESS_TOKEN=

# LLM API
DEEPSEEK_API_KEY=

# Database URL (auto-constructed in Docker)
DATABASE_URL=postgresql://antone:your_secure_password_here@postgres:5432/antone

# Authentication
JWT_SECRET=your_jwt_secret_here

# External Services
HEALTHCHECKS_IO_UUID=
CLOUDFLARE_TUNNEL_TOKEN=

# Backup Configuration
BACKBLAZE_KEY_ID=
BACKBLAZE_APPLICATION_KEY=
BACKBLAZE_BUCKET_NAME=antone-backups
```

### File Structure
[Source: architecture.md#3-repository-structure]

```
docker/
‚îú‚îÄ‚îÄ docker-compose.yml          # Base configuration
‚îú‚îÄ‚îÄ docker-compose.dev.yml      # Development overrides
‚îú‚îÄ‚îÄ docker-compose.prod.yml     # Production overrides
‚îî‚îÄ‚îÄ cloudflared/
    ‚îî‚îÄ‚îÄ config.yml              # Cloudflare Tunnel config

scripts/
‚îú‚îÄ‚îÄ backup-db.sh               # Database backup script
‚îî‚îÄ‚îÄ restore-db.sh              # Database restore script
```

---

## Testing

### Test File Location
Integration tests for Docker setup in `backend/tests/integration/`

### Testing Standards
- Verify all containers start successfully
- Verify health checks pass
- Test network connectivity between services
- Test data persistence across restarts

### Story-Specific Testing Requirements
1. Run `docker-compose up -d` and verify all services healthy
2. Connect to postgres from backend container
3. Stop and restart containers, verify data persists
4. Test Cloudflare tunnel connectivity (if configured)

---

## Change Log

| Date | Version | Description | Author |
|------|---------|-------------|--------|
| 2024-12-01 | 1.0 | Initial story draft | Bob (SM Agent) |
| 2024-12-02 | 1.1 | Architectural review: Added CRITICAL and HIGH risk mitigation for Docker deployment (OPS-001), Dockerfile builds (TECH-001), and health checks (OPS-002). Added verification scripts, troubleshooting guide, enhanced Dockerfile with proper workspace resolution, binding fixes for health checks. Added Tasks 14-20 for comprehensive testing and documentation. | Winston (Architect) |
| 2024-12-02 | 1.2 | **COMPREHENSIVE QA-DRIVEN UPDATE**: Integrated complete enhanced risk assessment (8 risks: 2 CRITICAL, 3 HIGH, 3 MEDIUM). **NEW CRITICAL RISK DATA-001**: Added irreversible data loss protection with external volumes and `dev-ctl.sh` safety wrapper script. **NEW HIGH RISK SEC-001**: Added secrets leakage prevention with .dockerignore and runtime-only secret injection. **NEW HIGH RISK PERF-001**: Optimized Dockerfile layer caching. Enhanced OPS-001 with hardened health checks (start_period, wget). Replaced TECH-001 Dockerfile with production-grade pnpm monorepo build pattern using `pnpm --filter`. Updated all tasks with risk IDs. Status: **NO-GO until all Critical/High mitigations implemented**. | Winston (Architect) |

---

## Dev Agent Record

### Agent Model Used
*To be filled by Dev Agent*

### Debug Log References
*To be filled by Dev Agent*

### Completion Notes List
*To be filled by Dev Agent*

### File List
*To be filled by Dev Agent*

---

## QA Results

### Review Date: 2025-12-02

### Reviewed By: Quinn (Test Architect)

### Code Quality Assessment

No code is available for review as this is a foundational infrastructure story in "Draft" status. The story provides an exceptionally detailed and high-quality plan, including production-grade Dockerfiles and comprehensive risk mitigation strategies.

### Refactoring Performed

None. No code to refactor.

### Compliance Check

- Coding Standards: ‚úì (Prescribed in story)
- Project Structure: ‚úì (Prescribed in story)
- Testing Strategy: ‚úì (Prescribed in story)
- All ACs Met: ‚úó (Not implemented)

### Improvements Checklist

- [ ] Implement all tasks as defined in the story.
- [ ] **CRITICAL**: Pay extreme attention to the mitigations for CRITICAL risks DATA-001 (Data Loss) and OPS-001 (Deployment Failures). The `dev-ctl.sh` wrapper script is mandatory.
- [ ] Verify all HIGH risk mitigations (TECH-001, SEC-001, PERF-001) are implemented correctly.
- [ ] Execute and validate the `verify-docker.sh` and `test-docker-build.sh` scripts.
- [ ] Document any new issues found during implementation in `DOCKER_TROUBLESHOOTING.md`.

### Security Review

The story includes CRITICAL and HIGH risk mitigations for security, specifically preventing data loss (DATA-001) and secret leakage into Docker images (SEC-001). The plan is robust.

### Performance Considerations

The story specifies a multi-stage Dockerfile build optimized for layer caching (PERF-001) and uses lightweight Alpine images. The plan is solid for performance.

### Files Modified During Review

None.

### Gate Status

Gate: CONCERNS ‚Üí `docs/qa/gates/1.2-docker-compose-infrastructure-setup.yml`
Risk profile: `docs/qa/assessments/1.2-risk-20251202.md`
NFR assessment: Not applicable for this foundational story.

### Recommended Status

‚úó **Changes Required** - The story is ready for a developer to *start* work. It should be moved to "In Progress" when development begins. It cannot be considered "Ready for Done" until all tasks, especially the critical risk mitigations, are implemented and thoroughly verified.
*To be filled by QA Agent*


### Review Date: 2025-12-04

### Reviewed By: Quinn (Test Architect)

### Code Quality Assessment

Excellent implementation quality. All critical and high-risk mitigations have been addressed robustly.
- **Data Safety**: `dev-ctl.sh` wrapper and external volumes effectively mitigate DATA-001.
- **Build Optimization**: `backend/Dockerfile` uses advanced pnpm strategies for caching.
- **Operational Reliability**: Health checks are hardened and resilient.

### Compliance Check

- Coding Standards: ‚úì (Followed)
- Project Structure: ‚úì (Followed)
- Testing Strategy: ‚úì (Verification scripts provided)
- All ACs Met: ‚úì (All files present and correct)

### Improvements Checklist

- [x] Implement all tasks as defined in the story.
- [x] **CRITICAL**: Pay extreme attention to the mitigations for CRITICAL risks DATA-001 (Data Loss) and OPS-001 (Deployment Failures). The `dev-ctl.sh` wrapper script is mandatory.
- [x] Verify all HIGH risk mitigations (TECH-001, SEC-001, PERF-001) are implemented correctly.
- [x] Execute and validate the `verify-docker.sh` and `test-docker-build.sh` scripts.
- [x] Document any new issues found during implementation in `DOCKER_TROUBLESHOOTING.md`.
- [ ] Story File Status: Update to "Ready for Done" (Dev Agent missed this).

### Gate Status

Gate: PASS ‚Üí `docs/qa/gates/1.2-docker-compose-infrastructure-setup.yml`
Risk profile: `docs/qa/assessments/1.2-risk-20251202.md`

### Recommended Status

‚úì **Ready for Done** - Implementation is complete and high quality. Proceed to Story 1.3.

### Review Date: 2025-12-04

### Reviewed By: Quinn (Test Architect)

### Code Quality Assessment
Docker foundation remains strong (Node 24 Alpine, external Postgres volume, health checks), but the worker container cannot start: `backend-worker` points to `backend/dist/workers/index.js`, which is not built. That means the stack never reaches a healthy steady state and ACs 7/8/9 regress. Backups/restores are scripted but unscheduled, so the ‚Äúdaily 02:00‚Äù requirement is still unmet.

### Refactoring Performed
None (review-only).

### Compliance Check
- Coding Standards: ‚úì
- Project Structure: ‚úó (worker entrypoint invalid)
- Testing Strategy: ‚úó (backup cadence not exercised/scheduled)
- All ACs Met: ‚úó (worker dead, backup schedule missing)

### Improvements Checklist
- [ ] Fix `backend-worker` command to the actual artifact (e.g., `backend/dist/workers/stream-monitor.js`) and verify the build produces it.
- [ ] Wire a scheduled backup run (cron/host scheduler) calling `scripts/backup-db.sh` nightly at 02:00 with 7-day retention; document restore verification.
- [ ] Re-run `docker-compose up` + health checks after the worker fix to validate AC7-9.

### Security Review
No new exposure; primary risk is operational blindness because the worker never comes online.

### Performance Considerations
Not measurable until the worker launches; current failure masks runtime behavior.

### Files Modified During Review
None.

### Gate Status

Gate: FAIL ‚Üí `docs/qa/gates/1.2-docker-compose-infrastructure-setup.yml`
Risk profile: `docs/qa/assessments/1.2-risk-20251202.md`
NFR assessment: Not produced.

### Recommended Status

‚úó **Changes Required** - Fix the worker entrypoint and schedule backups before treating this stack as releasable.
