# Story 3.7: Self-Correction Mechanism

## Status: Draft

## Story

**As a** the system,  
**I want** to autonomously delete my own posts that receive severe negative backlash,  
**so that** I can minimize reputation damage from mistakes without human intervention.

## Acceptance Criteria

1. Self-correction service at `@backend/services/self-correction.ts`
2. Service monitors posted replies every 15 minutes for sentiment/backlash
3. Negative signals collected:
   - Sentiment analysis of text responses (target: <-0.75)
   - Report/removal events from platform APIs
   - Trusted user flags (verified users, moderators)
4. Deletion triggers (ALL must be met):
   - Sentiment <-0.75 across ≥30 unique replies OR mod warning
   - Negativity Velocity >3× baseline average
   - At least one trusted signal flag
   - No "override" tag (for Controlled Assertiveness posts)
5. If triggered: Delete post via platform API, log incident, flag for human review
6. Escalation: Severe backlash (>100 negative replies) triggers immediate alert
7. Unit tests validate deletion logic doesn't trigger on minor negative feedback
8. Integration test: Simulate backlash scenario, verify deletion occurs
9. Self-deletion rate tracked in Safety KPIs (<2% target)

---

## Tasks / Subtasks

- [ ] **Task 1: Create Self-Correction Service** (AC: 1, 2)
  - [ ] Create `backend/src/services/self-correction.ts`
  - [ ] Implement monitoring loop (15 min interval)
  - [ ] Query posted replies
  - [ ] Fetch responses from platforms

- [ ] **Task 2: Implement Sentiment Collection** (AC: 3)
  - [ ] Fetch replies to our posts
  - [ ] Run sentiment analysis
  - [ ] Calculate average sentiment
  - [ ] Detect <-0.75 threshold

- [ ] **Task 3: Implement Trusted User Detection** (AC: 3)
  - [ ] Check if responder is verified
  - [ ] Check if responder is moderator
  - [ ] Flag as trusted signal

- [ ] **Task 4: Implement Deletion Logic** (AC: 4)
  - [ ] Check ALL conditions met
  - [ ] Sentiment <-0.75 AND ≥30 replies
  - [ ] OR mod warning
  - [ ] Negativity velocity >3× baseline
  - [ ] At least one trusted signal
  - [ ] No override tag

- [ ] **Task 5: Implement Post Deletion** (AC: 5)
  - [ ] Delete via Twitter API
  - [ ] Delete via Reddit API
  - [ ] Delete via Threads API
  - [ ] Update reply.deleted_at
  - [ ] Store delete_reason

- [ ] **Task 6: Implement Escalation** (AC: 6)
  - [ ] Detect severe backlash (>100 negative)
  - [ ] Create escalation record
  - [ ] Send immediate alert
  - [ ] Flag for human review

- [ ] **Task 7: Add to Worker Manager** (AC: 1)
  - [ ] Register in WorkerManager
  - [ ] Run every 15 minutes

- [ ] **Task 8: Track Safety KPI** (AC: 9)
  - [ ] Track self-deletion rate
  - [ ] Target <2%
  - [ ] Alert if exceeded

- [ ] **Task 9: Write Unit Tests** (AC: 7)
  - [ ] Test minor negative doesn't trigger
  - [ ] Test all conditions required
  - [ ] Test override tag prevents deletion

- [ ] **Task 10: Write Integration Test** (AC: 8)
  - [ ] Simulate backlash scenario
  - [ ] Verify deletion occurs
  - [ ] Verify escalation created

---

## Dev Notes

### Self-Correction Service Implementation
```typescript
// backend/src/services/self-correction.ts

import { prisma } from '../db';
import { twitterClient } from '../platforms/twitter/client';
import { redditClient } from '../platforms/reddit/client';
import { threadsClient } from '../platforms/threads/client';
import { logger } from '../utils/logger';

interface BacklashSignals {
  averageSentiment: number;
  responseCount: number;
  negativeVelocity: number;
  trustedSignals: number;
  moderatorWarning: boolean;
}

export class SelfCorrectionService {
  private intervalMs = 15 * 60 * 1000; // 15 minutes
  private baselineNegativity = -0.30; // Average baseline

  async start(): Promise<void> {
    logger.info('Self-Correction Service starting');

    while (true) {
      try {
        await this.monitorReplies();
      } catch (error) {
        logger.error('Self-correction cycle failed', { error });
      }

      await this.sleep(this.intervalMs);
    }
  }

  private async monitorReplies(): Promise<void> {
    // Get recently posted replies (last 24 hours)
    const replies = await prisma.reply.findMany({
      where: {
        postedAt: {
          gte: new Date(Date.now() - 24 * 60 * 60 * 1000),
        },
        deletedAt: null,
      },
      include: {
        decision: {
          include: { post: true },
        },
      },
    });

    for (const reply of replies) {
      const signals = await this.collectBacklashSignals(reply);

      if (this.shouldDelete(signals, reply)) {
        await this.deleteReply(reply, signals);
      } else if (this.shouldEscalate(signals)) {
        await this.escalateToHuman(reply, signals);
      }
    }
  }

  private async collectBacklashSignals(reply: any): Promise<BacklashSignals> {
    const responses = await this.fetchResponses(reply);

    // Sentiment analysis
    const sentiments = responses.map(r => this.analyzeSentiment(r.text));
    const averageSentiment = sentiments.reduce((sum, s) => sum + s, 0) / sentiments.length || 0;

    // Trusted signals
    const trustedSignals = responses.filter(r => r.isVerified || r.isModerator).length;

    // Negativity velocity
    const negativeVelocity = Math.abs(averageSentiment / this.baselineNegativity);

    // Moderator warning
    const moderatorWarning = responses.some(r => 
      r.isModerator && r.text.toLowerCase().includes('warning')
    );

    return {
      averageSentiment,
      responseCount: responses.length,
      negativeVelocity,
      trustedSignals,
      moderatorWarning,
    };
  }

  private shouldDelete(signals: BacklashSignals, reply: any): boolean {
    // Check override tag (Controlled Assertiveness)
    if (reply.decision.safetyFlags.includes('OVERRIDE')) {
      return false;
    }

    // ALL conditions must be met
    const sentimentThreshold = 
      (signals.averageSentiment < -0.75 && signals.responseCount >= 30) ||
      signals.moderatorWarning;

    const velocityThreshold = signals.negativeVelocity > 3.0;
    const trustedSignal = signals.trustedSignals >= 1;

    return sentimentThreshold && velocityThreshold && trustedSignal;
  }

  private shouldEscalate(signals: BacklashSignals): boolean {
    return signals.responseCount > 100 && signals.averageSentiment < -0.70;
  }

  private async deleteReply(reply: any, signals: BacklashSignals): Promise<void> {
    const platform = reply.platform;
    const postId = reply.platformPostId;

    try {
      // Delete from platform
      switch (platform) {
        case 'TWITTER':
          await twitterClient.deleteTweet(postId);
          break;
        case 'REDDIT':
          await redditClient.deleteComment(postId);
          break;
        case 'THREADS':
          await threadsClient.deleteReply(postId);
          break;
      }

      // Update database
      await prisma.reply.update({
        where: { id: reply.id },
        data: {
          deletedAt: new Date(),
          deleteReason: `Auto-deleted: Severe backlash (sentiment: ${signals.averageSentiment})`,
        },
      });

      // Create escalation for review
      await prisma.escalation.create({
        data: {
          replyId: reply.id,
          reason: 'BACKLASH_SPIKE',
          priority: 'HIGH',
          status: 'PENDING',
        },
      });

      logger.warn('Reply auto-deleted due to backlash', {
        replyId: reply.id,
        signals,
      });
    } catch (error) {
      logger.error('Failed to delete reply', { error, replyId: reply.id });
    }
  }

  private async escalateToHuman(reply: any, signals: BacklashSignals): Promise<void> {
    await prisma.escalation.create({
      data: {
        replyId: reply.id,
        reason: 'BACKLASH_SPIKE',
        priority: 'CRITICAL',
        status: 'PENDING',
      },
    });

    logger.error('CRITICAL: Severe backlash detected', {
      replyId: reply.id,
      responseCount: signals.responseCount,
      sentiment: signals.averageSentiment,
    });
  }

  private async fetchResponses(reply: any): Promise<any[]> {
    // Fetch responses from platform APIs
    // Implementation depends on platform
    return [];
  }

  private analyzeSentiment(text: string): number {
    // Simple sentiment (-1 to 1)
    // Negative words
    const negative = ['terrible', 'spam', 'shill', 'scam', 'bot', 'awful'];
    // Positive words
    const positive = ['thanks', 'helpful', 'great', 'appreciate'];

    let score = 0;
    for (const word of negative) {
      if (new RegExp(`\\b${word}\\b`, 'i').test(text)) score -= 0.3;
    }
    for (const word of positive) {
      if (new RegExp(`\\b${word}\\b`, 'i').test(text)) score += 0.3;
    }

    return Math.max(-1, Math.min(1, score));
  }

  private sleep(ms: number): Promise<void> {
    return new Promise(resolve => setTimeout(resolve, ms));
  }
}

export const selfCorrectionService = new SelfCorrectionService();
```

### File Structure
```
backend/src/
├── services/
│   └── self-correction.ts       # THIS STORY
└── workers/
    └── index.ts                 # Updated with self-correction
```

---

## Testing

### Test File Location
- `backend/tests/unit/services/self-correction.test.ts`

### Testing Standards
- Mock platform APIs
- Test deletion logic
- Test escalation logic

### Story-Specific Testing Requirements
1. Minor negative doesn't trigger deletion
2. All conditions required for deletion
3. Override tag prevents deletion
4. Severe backlash (>100) escalates
5. Deletion updates database
6. Platform API called correctly

---

## Change Log

| Date | Version | Description | Author |
|------|---------|-------------|--------|
| 2024-12-01 | 1.0 | Initial story draft | Bob (SM Agent) |

---

## Dev Agent Record
*To be filled by Dev Agent*

---

## QA Results
*To be filled by QA Agent*













